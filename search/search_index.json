{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"nf-core/rnaseq tutorial","text":""},{"location":"#welcome","title":"Welcome","text":"<p>These pages are a tutorial workshop for the Nextflow pipeline nf-core/rnaseq.</p> <p>In this workshop, we will recap the application of next generation sequencing to identify differentially expressed genes. You will learn how to use the rnaseq pipeline out this data-intensive workflow efficiently. We will cover topics such as configuration of the pipeline, code execution and data interpretation.</p> <p>Please note that this is not an introductory workshop, and we will assume some basic familiarity with Nextflow.</p> <p>By the end of this workshop, you will be able to:</p> <ul> <li>understand the key concepts behind RNAseq differential expression analysis, as adopted in this pipeline</li> <li>analyse simple NGS datasets with the nf-core/rnaseq workflow </li> <li>customise some of its features for your own analyses</li> <li>integrate different sources of information to interpret the results</li> </ul> <p>Let's get started!</p>"},{"location":"#running-with-gitpod","title":"Running with Gitpod","text":"<p>In order to run this using GitPod, please make sure:</p> <ol> <li>You have a GitHub account: if not, create one here</li> <li>Once you have a GitHub account, sign up for GitPod using your GitHub user here choosing \"continue with GitHub\".</li> </ol> <p>Now you're all set and can use the following button to launch the service:</p> <p></p>"},{"location":"#additional-documentation","title":"Additional documentation","text":"<ul> <li>You can find detailed documentation on Nextflow here</li> <li>You can find additional training on these pages</li> </ul>"},{"location":"#credits-copyright","title":"Credits &amp; Copyright","text":"<p>This training material has been written --- and aimed at anyone who is interested in using nf-core pipelines for their studies or research activities.</p> <p>The Docker image and Gitpod environment used in this repository have been created by Seqera but have been made open-source (CC BY-NC-ND) for the community.</p> <p>All examples and descriptions are licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.</p>"},{"location":"de_rstudio/","title":"Differential Analysis with DESeq2","text":"<p>In this section of the tutorial, we will guide you through the practical steps necessary to set up the RStudio environment and perform a differential expression analysis using DESeq2. Building on the theoretical foundations established earlier, we will now focus on the hands-on implementation of the DESeq2 workflow. We will cover all the necessary steps to prepare your RStudio environment, load the required libraries and data, and execute the DESeq2 analysis. By the end of this section, you will have a fully functional DESeq2 analysis pipeline set up in RStudio, ready to uncover the differentially expressed genes in your dataset.</p>"},{"location":"de_rstudio/#launching-the-rstudio-environment","title":"Launching the RStudio environment","text":"<p>Once the nf-core/rnaseq pipeline is terminated, the resulting data are stored in the folder results_star_salmon. No we can analyze the results by running DESeq2 on RStudio. First of all, we need to launch it:</p> <pre><code>sudo rstudio-server start\n</code></pre> <p>A pop-up will appear and by clicking on Open, we will be redirected to the RStudio login page. By inserting the username and the password reported below, we will be able to connect to RStudio:</p> <pre><code>Username: gitpod\nPassword: pass\n</code></pre> <p>To prevent losing connection, go back to gitpod and type on the Terminal:</p> <pre><code>sleep 2h\n</code></pre> <p>This command will keep the gitpod session active for exactly 2 hours, providing sufficient time to complete our analysis without interruption.</p> <p></p> <p>Now come back to our RStudio session.</p>"},{"location":"de_rstudio/#differential-expression-analysis","title":"Differential Expression Analysis","text":"<p>As in all analysis, firstly we need to create a new project:</p> <p>1) Go to the File menu and select New Project;</p> <p>2) Select New Directory, New Project, name the new directory /workspace/gitpod/training/DE_analysis/ and click on Create Project;</p> <p>3) The new project will be automatically opened in RStudio</p> <p>We can check whether we are in the correct working directory with getwd(). The path \"/workspace/gitpod/training/DE_analysis/\" should appear on your console. To store our results in an organized way, we will create a folder named de_results using the New Folder button in the bottom right panel. We will save all our resulting tables and plots in this folder. Next, go to the File menu, select New File, and then R Script to create a script editor in which we will save all commands required for the analysis. In the editor type:</p> <pre><code>#### Differential expression analysis with DESeq2 ####\n</code></pre> <p>and save the file as de_script.R. From now on, each command described in the tutorial can be added to your script. The resulting working directory should look like this:</p> <p></p> <p>The analysis requires several R packages. To utilize them, we need to load the following libraries:</p> <pre><code>#### Loading libraries ####\n\n# tidyverse: a collection of R packages for data manipulation, visualization and modeling\n\nlibrary(\"tidyverse\")\n\n# DESeq2: package for differential gene expression analysis\n\nlibrary(\"DESeq2\")\n\n# pheatmap: a package for creating heatmaps, which will be used to visualize the results\n\ninstall.packages(\"pheatmap\") # To install the package missing in the current RStudio env\n\nlibrary(\"pheatmap\")\n\n# RColorBrewer: a package for creating color palettes, which will be used to customize the heatmaps\n\nlibrary(\"RColorBrewer\")\n\n# ggrepel: a package that provides a geom for ggplot2 to create repulsive text labels, which can be useful for avoiding overlapping labels in plots\n\nlibrary(\"ggrepel\")\n</code></pre> <p>and the pre-computed DESeq2 object (dds) generated by the nfcore/rnaseq pipeline:</p> <pre><code>#### Import the dds obtained from nfcore/rnaseq ####\n\nload(\"/workspace/gitpod/training/results_star_salmon/star_salmon/deseq2_qc/deseq2.dds.RData\")\n</code></pre> <p>In this tutorial we will analyze the dds object generated by running the alignment with STAR and the quantification with Salmon. Alternatively, a user could choose to analyze the the dds object obtained by the nfcore rnaseq pipeline running only Salmon for both pseudoalignment and quantification. The file is stored in /workspace/gitpod/training/results_star_salmon/salmon/deseq2_qc/deseq2.dds.RData</p> <p>In DESEq2, the dds object is a central data structure that contains the following components:  - countData: a matrix of raw count data, where each row represents a gene, and each column represents a sample. - colData: a data frame containing information about the samples, such as the experimental design, treatment, and other relevant metadata. - design: a formula specifying the experimental design utilized to estimate the dispersion and the log2foldchange.</p> <p>All these components can be checked with specific command:</p> <pre><code>#### dds inspection ####\n\nhead(counts(dds)) # to check the raw counts\n\ncolData(dds) # to check the sample info\n\ndesign(dds) # to check the design formula\n</code></pre> <p>The inspection of the dds revealed that the colData and the design must be re-organized prior to the analysis. With the following commands we will rename the column of the colData, we will ensure that the rownames of the metadata are present in the same order as the column names and we reconstruct the colData. Notice that with this operation we also eliminate the sizeFactors already estimated by the nfcore DESeq2 module</p> <pre><code>#### Creation of metadata starting from the dds colData ####\n\nmetadata &lt;- DataFrame(\n    sample = colData(dds)$sample,\n    condition = colData(dds)$Group1,\n    replica = colData(dds)$Group2\n)\n\n# Assign names to rows of metadata\n\nrownames(metadata) &lt;- colnames(counts(dds))\n\n# Fill the dds colData with the generated metadata\n\ncolData(dds) &lt;- metadata\n</code></pre> <p>To avoid errors in DESeq2 is essential to check that sample names match between the colData and the countData, and that the sample are in the correct order:</p> <pre><code>#### Check that sample names match in both files ####\n\nall(colnames(dds$counts) %in% rownames(metadata)) # Must be TRUE\n\nall(colnames(dds$counts) == rownames(metadata)) # Must be TRUE\n</code></pre> <p>Now that everything is setted up, we can proceed to generate a new DESeq2 object with the corrected metadata and the right design:</p> <pre><code>#### Creation of a new dds ####\n\ndds_new  &lt;- DESeqDataSet(dds, design = ~ condition)\n\n# dds inspection \n\nhead(counts(dds_new)) # to check the raw counts\n\ncolData(dds_new) # to check the sample info\n\ndesign(dds_new) # to check the design formula\n</code></pre> <p>Analyzing the structure of the newly created dds, we can observe the differences:</p> <p></p> <p>Before running the different steps of the analysis, a good practice consists in pre-filtering the genes to remove those with very low counts. This is useful to improve computional efficiency and enhance interpretability. In general, it is reasonable to keep only genes with a counts of at least 10 for a minimal number of samples of 3:</p> <pre><code>#### Pre-filtering ####\n\n# Select a minimal number of samples = 3\n\nsmallestGroupSize &lt;- 3 \n\n# Select genes with a sum counts of at least 10 in 3 samples\n\nkeep &lt;- rowSums(counts(dds_new) &gt;= 10) &gt;= smallestGroupSize \n\n# Keep only the genes that pass the threshold\n\ndds_filtered &lt;- dds_new[keep,] \n</code></pre> <p>The next step in the DESeq2 workflow is to perform quality control (QC) analysis on our data. This analysis is crucial for identifying potential issues or biases and ensuring the data are suitable for downstream analysis. For QC analysis, it is useful to work with transformed versions of the count data. Raw count data are not suitable for these methods due to their discrete nature and the fact that their variance tends to increase with the mean. To address this, DESeq2 provides two types of transformations: variance stabilizing transformations (vst) and regularized logarithm (rlog). These transformations help to remove the dependence of the variance on the mean, making the data more suitable for visualization and exploratory analysis. While, the rlog is more robust to outliers and extreme values, vst is computationally faster and so preferred for larger dataset. It's important to remember that these transformations are used for visualization purposes, while DESeq2 itself operates on raw counts for differential expression analysis.</p> <pre><code>#### Transform normalized counts for data viz ####\n# A user can choose among vst and rlog. In this tutorial we will work with rlog transformed data.\n\nrld &lt;- rlog(dds_filtered, blind = TRUE)\n</code></pre> <p>The rlog and the vst transformations have an argument, blind that can be set to: - TRUE (default): useful for QC analysis because it re-estimates the dispersion, allowing for comparison of samples in an unbiased manner with respect to experimental conditions; - FALSE: the function utilizes the already estimated dispersion, generally applied when differences in counts are expected to be due to the experimental design.</p> <p>Next, we perform Principal Component Analysis (PCA) to visualize the data. DESeq2 provides a built-in function, plotPCA, which uses ggplot2 for visualization, taking the rld object as input. Since the treatment is the principal condition of interest in our metadata, we will use the condition information from our metadata to plot the PCA: </p> <pre><code>#### Plot PCA ####\n\nplotPCA(rld, intgroup = \"condition\")\n</code></pre> <p>The second essential step in QC analysis is hierarchical clustering. Although DESeq2 does not have a built-in function for this analysis, we can use the pheatmap() function from the pheatmap package. We will extract the matrix of rlog-transformed counts from the rld object (pheatmap input), compute pairwise correlations and plot the heatmap:</p> <pre><code>#### Plot sample to sample distance (hierarchical clustering) ####\n\n# Extract the matrix of rlog-transformed counts from the rld object\n\nsampleDists &lt;- dist(t(assay(rld)))  # Calculate pairwise distances between samples using the dist() function with Euclidean distance as the default method. By transposing the matrix with t(), we ensure that samples become rows and genes become columns, so that the dist function computes pairwise distances between samples.\n\n# Convert distances to a matrix\n\nsampleDistMatrix &lt;- as.matrix(sampleDists)  \n\n# Set the row and column names of the distance matrix\n\nrownames(sampleDistMatrix) &lt;- paste(rld$condition, rld$replica, sep = \"_\")\n\ncolnames(sampleDistMatrix) &lt;- paste(rld$condition, rld$replica, sep = \"_\")\n\n# Define a color palette for the heatmap\n\ncolors &lt;- colorRampPalette(rev(brewer.pal(9, \"Greens\")))(255) # function from RColorBrewer package\n\n# Create the heatmap\n\npheatmap(sampleDistMatrix, \n        clustering_distance_rows = sampleDists, \n        clustering_distance_cols = sampleDists, \n        col = colors, \n        fontsize_col = 8, \n        fontsize_row = 8)\n</code></pre> <p>Now, it is time to run the differential expression analysis with the DESeq() function:</p> <pre><code>#### Run the DESeq2 analysis ####\n\ndds_final &lt;- DESeq(dds_filtered)\n</code></pre> <p>The DESeq() function is a high-level wrapper that simplifies the process of differential expression analysis by combining multiple steps into a single function call:</p> <p></p> <p>This makes the workflow more user-friendly and ensures that all necessary preprocessing and statistical steps are executed in the correct order. The key functions that DESeq2 calls include:  - estimateSizeFactors: to normalize the count data; - estimateDispersion: to estimate the dispersion; - nbinomWaldTest: to perform differential expression test.</p> <p>The individual functions can be carried out also singularly as shown below:</p> <pre><code>#### Differential expression analysis step-by-step ####\n\ndds &lt;- estimateSizeFactors(dds)\n\ndds &lt;- estimateDispersions(dds)\n\ndds &lt;- nbinomWaldTest(dds)\n</code></pre> <p>The normalized counts stored in the dds can be inspected with the counts() function and saved in our results folder:</p> <pre><code>#### Inspect the normalized counts ####\n\n# Convert the normalized counts from the DESeq2 object to a data frame\n\nnormalized_counts &lt;- as.data.frame(counts(dds_final, normalized = TRUE))\n\n# Add a column for gene names to the normalized counts data frame\n\nnormalized_counts$gene &lt;- rownames(counts(dds_final))\n\n# Convert the data frame to a tibble for easier manipulation and relocate the gene column to the first position\n\nnormalized_counts &lt;- as_tibble(normalized_counts) %&gt;% \n  relocate(gene, .before = control_rep1)\n\n# Display the first few rows of the normalized counts to inspect the data\n\nhead(counts(dds_final, normalized = TRUE))\n\n# Display the first few rows of the raw counts (not normalized) to compare with the normalized counts\n\nhead(counts(dds_final))\n\n# Save normalized counts \n\nwrite.csv(normalized_counts, file = \"de_results/normalized_counts.csv\")\n</code></pre> <p>The results() function in DESeq2 is used to extract the results of the differential expression analysis. This function takes the dds object as input and returns a DataFrame containing the results of the analysis:</p> <ul> <li>baseMean: the average expression level of the gene across all samples;</li> <li>log2FoldChange: the log2 fold change of the gene between the condition of interest and the reference level;</li> <li>lfcSE: the standard error of the log2 fold change;</li> <li>stat: the Wald statistic, which is used to calculate the p-value;</li> <li>pvalue: the p-value associated with the Wald test, which indicates the probability of observing the log2 fold change by chance;</li> <li>padj: the adjusted p-value, which takes into account multiple testing corrections;</li> </ul> <p>By default, the results() function returns the results for all genes in the analysis with an adjusted p-value below a specific FDR (false discovery rate) cutoff, set by the default to 0.1. This threshold can be modified with the parameter alpha. The results() function can also be customized to extract specific columns or rows of interest, and can also be used to filter the results based on certain criteria, such as a minimum log2 fold change or a maximum adjusted p-value or to set a specific contrast. The contrast argument in the results() function is used to specify the contrast of interest for which the results should be extracted. A contrast is a specific comparison between two or more levels of a factor, such as the comparison between the treatment and control groups. The order of the contrast names determines the direction of the fold change that is reported in the results. Specifically, the first level of the contrast is the condition of interest, and the second level is the reference level. Notice that in the tutorial the contrast is already correct.</p> <pre><code>#### Extract results table from the dds object ####\n\nres &lt;- results(dds_final)\n\n# Visualize the results\n\nhead(res) \n\n # Summarize the results showing the number of tested genes (genes with non-zero total read count), the genes up- and down-regulated at the selected threshold (alpha) and the number of genes excluded by the multiple testing due to a low mean count \n\nsummary(res)\n\n# DESeq2 function to extract the name of the contrast\n\nresultsNames(dds_final) \n\n# contrast &lt;- c(\"name_of_design_formula\", \"condition_of_interest\", \"reference_level\") # Command to set the contrast, if necessary\n\n# Store the res object inside another variable because the original res file will be required for other functions\n\nres_viz &lt;- res\n\n# Add gene names as a new column to the results table\n\nres_viz$gene &lt;- rownames(res)\n\n# Convert the results to a tibble for easier manipulation and relocate the gene column to the first position\n\nres_viz &lt;- as_tibble(res_viz) %&gt;% relocate(gene, .before = baseMean)\n\n# Save the results table \n\nwrite.csv(res_viz, file = \"de_results/de_result_table.csv\")\n</code></pre> <p>In the Experimental Design section, we emphasized the importance of estimating the log2 fold change threshold using a statistical power calculation, rather than selecting it arbitrarily. This approach ensures that the chosen threshold is statistically appropriate and tailored to the specifics of the experiment. However, since we are working with simulated data for demonstration purposes, we will use a padj (adjusted p-value) threshold of 0.05 and consider genes with a log2 fold change greater than 1 or lower than -1 as differentially expressed.</p> <pre><code>#### Extract significant DE genes from the results ####\n\n# Filter the results to include only significantly differentially expressed genes with an adjusted p-value (padj) less than 0.05 and a log2foldchange greater than 1 or less than -1\n\nresSig &lt;- subset(res_viz, padj &lt; 0.05 &amp; abs(log2FoldChange) &gt; 1) \n\n# Convert the results to a tibble for easier manipulation and relocate the 'Gene' column to be the first column\n\nresSig &lt;- as_tibble(resSig) %&gt;% relocate(gene, .before = baseMean) \n\n# Order the significant genes by their adjusted p-value (padj) in ascending order\n\nresSig &lt;- resSig[order(resSig$padj),] \n\n# Display the final results table of significant genes\n\nresSig \n\n# Save the significant DE genes \n\nwrite.csv(resSig, file = \"de_results/sig_de_genes.csv\")\n</code></pre> <p>Now that we have obtained the results of the differential expression analysis, it's time to visualize the data to gain a deeper understanding of the biological processes that are affected by the experimental conditions. Visualization is a crucial step in RNA-seq analysis, as it allows us to identify patterns and trends in the data that may not be immediately apparent from the numerical results. In the following sections, we will explore different types of plots that are commonly used to visualize the results of RNA-seq analysis, including:</p> <ul> <li>MA plot: it is a type of scatter plot that is commonly used to visualize the results of differential expression analysis for all the samples. The plot displays the log2 fold change on the y-axis and the mean of the normalized counts on the x-axis. This allows for the visualization of the relationship between the magnitude of the fold change and the mean expression level of the genes. Genes that are highly differentially expressed will appear farthest from the horizontal axis, while genes with low expression levels will appear closer to the axis. MA plots are useful for identifying genes that are both highly expressed and highly differentially expressed between two conditions.</li> </ul> <pre><code>#### MA plot ####\n\nplotMA(res, ylim = c(-2,2))\n</code></pre> <ul> <li>counts plot: it plots the normalized counts for a single gene across the different conditions in your experiment. It\u2019s particularly useful for visualizing the expression levels of specific genes of interest and comparing them across sample groups.</li> </ul> <pre><code>#### Plot a specific gene in this case ENSG00000142192, a DE gene ####\n\nplotCounts(dds_new, gene = \"ENSG00000142192\")\n</code></pre> <ul> <li>volcano plot: it is a type of scatter plot that displays the log2 fold change on the x-axis and the log transformed padj on the y-axis. This allows for the visualization of both the magnitude and significance of the changes in gene expression between two conditions. Genes that are highly differentially expressed (i.e., have a large log2 fold change) and are statistically significant (i.e., have a low padj) will appear in the top-left or top-right corners of the plot, making it easy to identify the most biologically meaningful changes.</li> </ul> <pre><code>#### Volcano plot ####\n\n# Convert the results to a tibble and add a column indicating differential expression status\n\nres_tb &lt;- as_tibble(res) %&gt;% \n  mutate(diffexpressed = case_when(\n    log2FoldChange &gt; 1 &amp; padj &lt; 0.05 ~ 'upregulated', \n    log2FoldChange &lt; -1 &amp; padj &lt; 0.05 ~ 'downregulated',\n    TRUE ~ 'not_de'\n  ))\n\n# Add a new column with gene names\n\nres_tb$gene &lt;- rownames(res) \n\n# Relocate the 'gene' column to be the first column\n\nres_tb &lt;-  res_tb %&gt;% \n  relocate(gene, .before = baseMean)\n\n# Order the table by adjusted p-value (padj) and add a new column for gene labels\n\nres_tb &lt;- res_tb %&gt;% arrange(padj) %&gt;% mutate(genelabels = \"\")\n\n# Label the top 5 most significant genes\n\nres_tb$genelabels[1:5] &lt;- res_tb$gene[1:5]\n\n# Create a volcano plot using ggplot2\n\nggplot(data = res_tb, aes(x = log2FoldChange, y = -log10(padj), col = diffexpressed)) + \n  geom_point(size = 0.6) + \n  geom_text_repel(aes(label = genelabels), size = 2.5, max.overlaps = Inf) +\n  ggtitle(\"DE genes treatment versus control\") + \n  geom_vline(xintercept = c(-1, 1), col = \"black\", linetype = 'dashed', linewidth = 0.2) +\n  geom_hline(yintercept = -log10(0.05), col = \"black\", linetype = 'dashed', linewidth = 0.2) +\n  theme(plot.title = element_text(size = rel(1.25), hjust = 0.5),\n        axis.title = element_text(size = rel(1))) +\n  scale_color_manual(values = c(\"upregulated\" = \"red\", \n                                \"downregulated\" = \"blue\", \n                                \"not_de\" = \"grey\")) +\n  labs(color = 'DE genes') +\n  xlim(-3,5)\n</code></pre> <p>heatmap: plot of the normalized counts for all the significant genes obtained with the pheatmap() function. The heatmap provides insights into genes and sample relationships that may not be apparent from individual gene plots alone. </p> <pre><code>#### Heatmap ####\n\n# Extract only the first column (gene names) from the result object containing the significant genes\n\nsignificant_genes &lt;- resSig[, 1]\n\n# Extract normalized counts for significant genes from the normalized counts matrix and convert the \"gene\" column to row names \n\nsignificant_counts &lt;- inner_join(normalized_counts, significant_genes, by = \"gene\") %&gt;% \n  column_to_rownames(\"gene\")\n\n# Create the heatmap using pheatmap\n\npheatmap(significant_counts, \n         cluster_rows = TRUE,\n         fontsize = 8,\n         scale = \"row\",\n         fontsize_row = 8,\n         height = 10)\n</code></pre>"},{"location":"de_rstudio/#functional-analysis","title":"Functional analysis","text":"<p>The output of the differential expression analysis is a list of significant differentially expressed genes (DEGs). To uncover the underlying biological mechanisms, various downstream analyses can be performed, such as functional enrichment analysis (identify overrepresented biological processes, molecular functions, or cellular components) and network analysis (group genes based on similar expression patterns and identify novel pathways or interactions). To facilitate interpretation of the resulting gene lists, a range of freely available web- and R-based tools can be employed.</p> <p>In this tutorial we will focus on the over Representation Analysis (ORA), also known as enrichment analysis, a powerful tool for identifying biological pathways or processes that are significantly enriched with differentially expressed genes. The underlying statistic behind ORA is the hypergeometric test, which calculates the probability of observing a certain number of genes from a particular pathway or process in the list of differentially expressed genes by chance. The hypergeometric test takes into account the total number of genes in the genome, the number of genes in the pathway or process, and the number of differentially expressed genes in the list. The resulting p-value represents the probability of observing the enrichment by chance, and a low p-value indicates that the enrichment is statistically significant. By applying the hypergeometric test to multiple pathways or processes, ORA provides a comprehensive view of the biological mechanisms underlying the differentially expressed genes, allowing researchers to identify key biological processes and pathways that are affected by the condition of interest.</p> <pre><code>#### Enrichment analysis (ORA) ####\n\n# Loading libraries\n\n# clusterProfiler: a package for enrichment analysis\n\nlibrary(clusterProfiler)\n\n# org.Hs.eg.db: a package for the human gene annotation database\n\nlibrary(org.Hs.eg.db)\n\n# cowplot: a package for combining multiple plots\n\ninstall.packages(\"cowplot\") # To install the package missing in the current RStudio env\n\nlibrary(cowplot)\n\n# Prepare gene list\n# Extract the log2 fold change values from the results data frame\n\ngene_list &lt;- res$log2FoldChange\n\n# Name the vector with the corresponding gene identifiers\n\nnames(gene_list) &lt;- res$gene\n\n# Sort the list in decreasing order (required for clusterProfiler)\n\ngene_list &lt;- sort(gene_list, decreasing = TRUE)\n\n# Extract the significantly differentially expressed genes from the results data frame\n\nres_genes &lt;- resSig$gene\n\n# Run GO enrichment analysis using the enrichGO function\n\ngo_enrich &lt;- enrichGO(\n  gene = res_genes,                # Genes of interest\n  universe = names(gene_list),     # Background gene set\n  OrgDb = org.Hs.eg.db,            # Annotation database\n  keyType = 'ENSEMBL',             # Key type for gene identifiers\n  readable = TRUE,                 # Convert gene IDs to gene names\n  ont = \"ALL\",                     # Ontology: can be \"BP\", \"MF\", \"CC\", or \"ALL\"\n  pvalueCutoff = 0.05,             # P-value cutoff for significance\n  qvalueCutoff = 0.10              # Q-value cutoff for significance\n)\n\n# Create a bar plot of the top enriched GO terms\n\nbarplot &lt;- barplot(\n  go_enrich, \n  title = \"Enrichment analysis barplot\",\n  font.size = 8\n)\n\n# Create a dot plot of the top enriched GO terms\n\ndotplot &lt;- dotplot(\n  go_enrich,\n  title = \"Enrichment analysis dotplot\",\n  font.size = 8\n)\n\n# Combine the bar plot and dot plot into a single plot grid\n\nplot_grid(barplot, dotplot, nrow = 2)\n</code></pre>"},{"location":"interpretation/","title":"Interpretation","text":"<p>Once the differential expression genes have been identified, the next crucial step is to interpret the results. This involves examining the tables and plots generated during the analysis to understand the biological implications of the data. In this part of the tutorial, we will delve into the results by discussing the significant genes identified, their expression patterns, and the visual representations of these findings. We will explore various tables and plots, such as volcano plots, MA plots, and heatmaps, to gain insights into the underlying biological processes and validate the reliability of our results.</p> <p>[!NOTE] The results illustrated in this section might show slight variations compared to your runs due to randomness in the STAR algorithm. This randomness arises from using variable seed values and parallel processing, leading to minor differences in results between runs on the same data. These small discrepancies are not biologically significant and may affect counts and subsequent plots (such as PCA and count plots). However, the overall patterns and main findings should remain consistent. While exact reproducibility is ideal, minor variations are acceptable in practice, as long as they do not impact the main conclusions of the study.</p> <p>The first plot we will examine is the Principal Component Analysis (PCA) plot. Since we're working with simulated data, our metadata is relatively simple, consisting of just three variables: sample, condition, and replica. In a typical RNA-seq experiment, however, metadata can be complex and encompass a wide range of variables that could contribute to sample variation, such as sex, age and developmental stage. </p> <p></p> <p>By plotting the PCA on the PC1 and PC2 axes, using [condition] as the main variable of interest, we can quickly identify the primary source of variation in our data. By accounting for this variation in our design model, we should be able to detect more differentially expressed genes related to [condition]. When working with real data, it's often useful to plot the data using different variables to explore how much variation is explained by the first two PCs. Depending on the results, it may be informative to examine variation on additional PC axes, such as PC3 and PC4, to gain a more comprehensive understanding of the data.</p> <p>Next, we will examine the hierarchical clustering plot to explore the relationships between samples based on their gene expression profiles. The heatmap is organized such that samples with similar expression profiles are close to each other, allowing us to identify patterns and structures in the data.</p> <p></p> <p>We can observe a high degree of correlation in the plot. Remember that to create this plot, we utilized the [dist()] function, so in the legend on the right, a value of 0 corresponds to high correlation, while a value of 5 corresponds to very low correlation. Similar to PCA, we can see that samples tend to cluster together according to [condition].</p> <p>Overall, the integration of these plots suggests that we are working with high-quality data and can confidently proceed to the differential expression analysis.</p> <p>From this point, we will examine plots that are generated after running the differential expression analysis. These plots are not quality control (QC) plots, but rather plots that help us interpret the results of the differential expression analysis.  After running the [results()] function, a good way to start to have an idea about the results of our differential expression analysis is to look at the MA plot. </p> <p></p> <p>By default, genes are coloured in blue if the padj is less than 0.1 and the log2foldchange greater than or less than 0. Genes that fall outside the plotting region are represented as open triangles. Note that we have not yet applied a filter to select only significant, which we define as those with a padj value less than 0.5 and a log2 fold change of at least 1 or -1.</p> <p>After filtering our genes of interest according to our threshold, let's have a look to our significatnt genes</p> <pre><code>gene                baseMean        log2FoldChange     lfcSE          stat            pvalue              padj\nENSG00000205726     121645.5908     2.894480           0.1515387      19.100600       2.496005e-81        5.840651e-79\nENSG00000142192     51065.3192      3.025489           0.1891258      15.997230       1.335883e-57        1.562983e-55\nENSG00000142156     20805.8078      2.977705           0.2159277      13.790287       2.915972e-43        2.274458e-41\nENSG00000159231     458.9277        -1.194777          0.3058100      -3.906926       9.347790e-05        5.468457e-03\nENSG00000156282     481.7624        1.095272           0.2969594      3.688289        2.257672e-04        1.056590e-02\n</code></pre> <p>After the identification of DE genes, it's informative to visualize the expression of specific genes of interest. Using the [plotCounts()] function directly on the [dds] object allows us to examine individual gene expression profiles without accessing the full [res] object.</p> <p></p> <p>In our example, post-treatment, we observe a significant increase in the expression of the ENSG00000142192 gene, highlighting its responsiveness to the experimental conditions.</p> <p>To gain a comprehensive overview of the transcriptional profile, the volcano plot represents a highly informative tool.</p> <p></p> <p>The treatment induced differential expression in five genes, with one downregulated and four upregulated. This plot visually represents the numerical results reported in the table above.</p> <p>Finally, we can create a heatmap using the normalized expression counts of genes identified as significantly differentially expressed. The resulting heatmap visualizes how the expression of significant genes varies across samples. Each row represents a gene, and each column represents a sample. The color intensity in the heatmap reflects the normalized expression levels: red colors indicate higher expression, while blue colors indicate lower expression.</p> <p></p> <p>By examining the heatmap, we can visually identify the expression patterns of our five significant differentially expressed genes. This visualization allows us to identify how these genes respond to the treatment. The heatmap provides a clear and intuitive way to explore gene expression dynamics and can guide further investigation into the DESEq processes underlying observed changes.</p>"},{"location":"interpretation/#over-representation-analysis-ora","title":"Over Representation Analysis (ORA)","text":"<p>Finally, we can attempt to assign biological significance to our differentially expressed genes through Enrichment Analysis (ORA). The ORA analysis identifies specific biological pathways, molecular functions, and cellular processes that are enriched with our differentially expressed genes.</p> <p></p> <p>Based on the results of the ORA, we identified two differentially expressed genes that appear to be involved in redox reduction, specifically in the reduction of carbonyl groups. Furthermore, these genes seem to play a role in the endoplasmic reticulum during clathrin-mediated endocytosis and endosome recycling. This suggests that they may be involved in metabolic pathways related to detoxification and/or xenobiotic metabolism.</p> <p>Note that this analysis is based on simulated data and serves only as a demonstration to illustrate the classical workflow of the analysis.</p>"},{"location":"interpretation/#conclusions","title":"Conclusions","text":"<p>In this tutorial, we have walked through the steps of performing differential expression analysis using DESeq2, from preparing the data to interpreting the results. We have seen how to identify differentially expressed genes, visualize the results, and perform enrichment analysis to gain insights into the biological significance of the results. By following this tutorial, you should now be able to perform differential expression analysis using DESeq2 and interpret the results in the context of your own research question. Remember to always carefully evaluate the quality of your data and the assumptions of the analysis, and to consider the biological relevance of the results in the context of your research.</p>"},{"location":"rnaseq/","title":"The nf-core/rnaseq pipeline","text":"<p>In order to carry out a RNA-Seq analysis we will use the nf-core pipeline rnaseq.</p>"},{"location":"rnaseq/#overview","title":"Overview","text":"<p>The pipeline is organised following the blocks we previously described: pre-processing, alignment (or pseudoalignment) and quantification and differential expression analysis.</p> <p></p> <p>In each process, the users can choose among a range of different options. Importantly, the users can decide to follow one of the two different routes in the alignment and quantification step: - alignment and quantification (stage 2); - pseudoalignment and quantification (stage 3). </p>"},{"location":"rnaseq/#experimental-design","title":"Experimental Design","text":"<p>In RNA-seq experimental design, the number of reads and the number of biological replicates are two critical factors that need to be carefully considered. While it may seem intuitive that having a large number of reads is always desirable, this is not necessarily the case. In fact, having an excessive number of reads can lead to unnecessary costs and computational burdens, without providing significant improvements in data quality or biological insight. Instead, it is often more beneficial to prioritize the number of biological replicates, as these allow for the capture of natural biological variation and provide a more accurate representation of the underlying biological phenomenon. Biological replicates involve collecting and sequencing RNA from separate biological samples from different individuals, different tissues, or different time points. They are essential for identifying genuine changes in gene expression and distinguishing them from technical noise. In contrast, technical replicates involve sequencing the same RNA sample multiple times to assess the technical variability of the sequencing platform and ensure consistency in the results. To ensure the validity of the results, it is crucial to carefully consider the trade-off between the number of biological replicates and sequencing depth. Higher sequencing depth can improve the ability to detect lowly expressed genes and provide more precise quantification of gene expression. However, beyond a certain threshold, increasing sequencing depth yields diminishing returns in terms of data quality and biological insight, making it important to find an optimal balance. Therefore, it is often more beneficial to prioritize biological replicates over simply increasing sequencing depth or technical replicates. Furthermore, the number of reads and biological replicates should be estimated through a calculation of the statistical power, which takes into account the desired fold change, alpha level, and effect size. This calculation can inform the experimental design and provide a basis for setting the log2 fold change (log2FC) threshold in the subsequent differential expression (DE) analysis. By incorporating multiple biological replicates into the experimental design, optimizing sequencing depth, and estimating the required number of reads and replicates through statistical power calculations, it is possible tp increase the statistical power of the analysis, reduce the risk of false positives, and gain a more comprehensive understanding of the biological system being studied.</p>"},{"location":"rnaseq/#library-design","title":"Library design","text":"<p>RNA-seq library design involves a range of critical decisions, including the choice between paired-end and single-end sequencing strategies. This choice is influenced by several key factors, such as fragment size selection, strand specificity preservation, and optimal read length determination. Paired-end sequencing, where both ends of a fragment are sequenced, provides valuable information about structural variations and transcript isoforms and can improve mapping accuracy, especially for longer transcripts and repetitive regions. In contrast, single-end sequencing, where only one end of the fragment is sequenced, can be more cost-effective while still providing high-quality data for gene expression analysis. The decision between paired-end and single-end sequencing ultimately depends on the research question and experimental goals. For instance, paired-end sequencing may be preferred if the focus is on identifying novel transcripts or characterizing transcript isoforms. However, if the primary goal is to quantify gene expression levels, single-end sequencing may be sufficient. The type of RNA being sequenced also plays a crucial role in library design, as different RNA species (e.g., mRNA, total RNA, small RNA) require distinct protocols. Additionally, the chosen read length can impact the ability to detect specific features, such as splice junctions or repeated regions. Therefore, the choice between paired-end and single-end reads in RNA-seq library design depends on the specific research goals, the nature of the RNA samples, budget constraints, alongside considerations for data analysis complexity and computational resources.</p>"},{"location":"rnaseq/#reference-genome","title":"Reference genome","text":"<p>nf-core pipelines make use of the Illumina iGenomes collection as reference genomes. Before starting the analysis, the users might want to check whether the genome they need is part of this collection. They also might want to consider downloading the reference locally, when running on premises: this would be useful for multiple runs and to speed up the analysis. In this case the parameter <code>--igenomes_base</code> might be used to pass the root directory of the downloaded references. </p> <p>One might also need to use custom files: in this case the users might either provide specific parameters at command line (<code>--fasta</code> option followed by the genome of choiche), or create a config file adding a new section to the <code>genome</code> object. See here for more details.</p> <p>We will follow this specific approach in this tutorial, since the data we will be using have been simulated on chromosome 21 of the Human GRCh38 reference, and we have prepared genome fasta and genome index containing only this chromosome locally. The two files are <code>/workspace/gitpod/training/data/refs/Homo_sapiens_assembly38_chr21.fa</code> and <code>/workspace/gitpod/training/data/refs/Homo_sapiens_assembly38_chr21.fa.fai</code>, respectively.</p>"},{"location":"rnaseq/#reference-annoation","title":"Reference annoation","text":"<p>The reference annotation plays a crucial role in the RNA-seq analysis. Without a high-quality reference annotation, RNA-seq analysis would be severely hindered, leading to inaccurate or incomplete results. The reference annotation provides a precise guide for aligning sequencing reads to specific genomic regions, allowing to identify the genes, transcripts and regulatory elements. This is particularly important for identifying novel transcripts and alternative splicing events. The reference annotation provides essential information about the structures of genes and transcripts, but it also includes information about gene ontology, pathways, and protein domains, which is essential for understanding the biological context of gene expression changes. </p> <p>nf-core pipelines make use of the Illumina iGenomes collection also as reference annotation. The reference annotations are vastly out of date with respect to current annotations and miss certain features. So, the general recommendation is to download a newest annotation version compatible with the genome. A user can utilize the <code>--gtf</code> or the <code>--gff</code> options to specify the annottation files of choiche, or create a config file adding a new section to the <code>genome</code> object. </p> <p>Similarly to the approach utilized for the genome, in this tutorial we will follow this approach. The annotation files include only the annotated transcripts on chromosome 21 of the Human GRCh38 reference genome, and we have already prepared these files locally. The two files are <code>/workspace/gitpod/training/data/refs/gencode_v29_chr21.gff</code> and <code>/workspace/gitpod/training/data/refs/gencode_v29_transcripts_chr21.fa</code>, respectively.</p>"},{"location":"rnaseq/#input-files","title":"Input files","text":"<p>The input data should be provided in a CSV file, according to a format that is largely common for nf-core pipelines. The format is described in the rnaseq usage page. The file is <code>/workspace/gitpod/training/data/reads/rnaseq_samplesheet.csv</code>.</p>"},{"location":"rnaseq/#running-nf-corernaseq","title":"Running nf-core/rnaseq","text":"<p>In the following sections we will: - prepare our references; - set our computational resources in order to be able to run the pipeline on a gitpod VM; - edit the filtering settings; - run the pipeline.</p>"},{"location":"rnaseq/#reference-and-annotation-files","title":"Reference and annotation files","text":"<p>Following the considerations above, we will first of all edit the <code>nextflow.config</code> file in our working directory to add a new genome. It is sufficient to add the following code to the <code>parameters</code> directive in the config.</p> <pre><code>igenomes_base = '/workspace/gitpod/training/data/refs/'\ngenomes {\n        'GRCh38chr21' {\n            fasta                 = \"${params.igenomes_base}/sequence/Homo_sapiens_assembly38_chr21.fasta\"\n            fasta_fai             = \"${params.igenomes_base}/sequence/Homo_sapiens_assembly38_chr21.fasta.fai\"\n            gff                   = \"${params.igenomes_base}/gencode_v29_chr21_parsed.gff\"\n            transcript_fasta      = \"${params.igenomes_base}/gencode.v29.transcripts_chr21.fa\"\n            star_index            = \"${params.igenomes_base}/star_index_chr21.tar.gz\"\n            salmon_index          = \"${params.igenomes_base}/salmon_index_chr21.tar.gz\"\n    }\n}\n</code></pre> <p>To speed up the analysis we will include the <code>star_index</code> and the <code>salmon_index</code> in the config. These files have already been created locally.</p>"},{"location":"rnaseq/#computing-resources","title":"Computing resources","text":"<p>Based on the choices we made when starting up the gitpod environment, we recommend to use the following additional parameters. They can also be added to the parameters directive in the config file we just edited.</p> <pre><code>params {\n    max_cpus      = 2\n    max_memory    = '6.5GB'\n    max_time      = '2.h'\n}\n</code></pre>"},{"location":"rnaseq/#launching-the-pipeline","title":"Launching the pipeline","text":"<p>Now we are ready to launch the pipeline, and we can use the following command line:</p> <pre><code>nextflow run nf-core/rnaseq -r 3.12.0 \\\n--input /workspace/gitpod/training/data/reads/rnaseq_samplesheet.csv \\\n--outdir ./results_star_salmon \\\n--genome GRCh38chr21 \\\n--aligner star_salmon \\\n--pseudo_aligner salmon \\\n--skip_biotype_qc \\\n--skip_stringtie \\\n--skip_bigwig \\\n--skip_umi_extract \\\n--skip_trimming \\\n--skip_fastqc \\\n--skip_markduplicates \\\n--skip_dupradar \\\n--skip_rseqc \\\n--skip_qualimap\n</code></pre>"},{"location":"theory/","title":"RNAseq Analysis","text":"<p>Before we dive into the nf-core pipeline used for the analysis of RNA-sequencing data, it's worth looking at some theoretical aspects of RNA-seq.</p>"},{"location":"theory/#overview","title":"Overview","text":"<p>Given the central role of RNA in a variety of cellular and molecular functions, RNA-seq has emerged as a powerful tool to measure the presence and levels of RNA species in biological samples. The technique is based on next-generation sequencing (NGS) technologies and is now considered the gold standard in the transcriptomic field.</p> <p>After RNA extraction and reverse transcription into complementary DNA (cDNA), the biological material is sequenced, generating NGS \"reads\" that correspond to the RNA captured and sequenced in a specific cell, tissue, or organ at a given time. The sequencing data are then bioinformatically processed through a typical workflow summarized in the diagram below:</p> <p>In the scheme, we can identify three different key phases in the workflow: data preprocessing, alignment and quantification, and finally, differential expression analysis. In the data preprocessing step, the raw reads are handled to remove adapters and contaminants, and their quality is checked. Then, reads are mapped to a genome reference, and the abundance of transcripts or genes is estimated. The workflow can also follow an additional route based on lightweight alignment and quantification, reducing the amount of time required for the analysis. Finally, differentially expressed genes or transcripts are identified using statistical tests, annotated, and visualized. Depending on the user's needs, the workflow can include additional downstream analyses such as functional enrichment analysis, coexpression analysis, and integration with other omics data.</p>"},{"location":"theory/#pre-processing","title":"Pre-processing","text":"<p>The pre-processing of sequencing reads from RNA-seq data is a critical step to ensure the quality and accuracy of downstream analysis. The raw reads obtained from the sequencer are stored as FASTQ files, which contain both the sequence data and quality scores. The initial processing step involves evaluating the quality of the reads and identifying potential issues such as sequencing errors, adapter contamination, or low-quality bases. Reads with low-quality bases or overall poor sequencing quality are removed to prevent them from affecting the accuracy of downstream analysis. Next, the presence of adapters (short DNA sequences ligated to the ends of DNA fragments during library preparation) is detected through comparison with known adapter sequences or using algorithms that identify adapter-like sequences, and removed in a process known as read trimming. Finally, reads containing contaminants (genomic DNA and/or rRNA) are filtered out, and the quality of the filtered reads is checked again to ensure their suitability for downstream processing.</p>"},{"location":"theory/#alignment-or-lightweight-alignment-and-quantification","title":"Alignment (or lightweight alignment) and quantification","text":"<p>In the RNA-seq workflow, the alignment step refers to the process of mapping sequencing reads to a reference genome or transcriptome with the goal of determining the position and orientation of each read relative to the reference sequence and allowing the subsequent gene expression quantification.</p> <p>Errors, gaps, or poor sequence quality regions, as well as insertions/deletions (INDELs), duplicated and repetitive regions make this step challenging. Addressing these issues during the alignment step, by choosing a high-quality reference and an appropriate aligner, is essential for obtaining accurate and reliable results. A crucial component in the RNA-seq workflow is the annotation file, either in form of General Feature Format file (GFF) or in form of Gene Transfer Format file (GTF). These file formats contain key information about the location and structure of genes and transcripts and are essential for both mapping sequencing reads accurately during the alignment step and to quantify genes expression in the quantification step. Additionally, RNA-seq data often include reads that span exon-exon junctions and the annotation files provide information about splice junctions allowing the inference of different isoforms.</p> <p>The aligment and quantification steps can follow two different routes according to user preferences: - alignment and quantification; - lightweight alignment and quantification.</p> <p>In the context of RNA-seq analysis, the alignment phase is often performed with splice-aware aligners that are utilized to take into account the splicing process. In addition to aligning reads across known splice junctions, splice-aware aligners also aim to detect novel splice junctions and alternative splicing events. Splice-aware aligners are optimized for speed and memory efficiency to handle the large volumes of RNA-seq data generated in modern sequencing experiments. They employ sophisticated algorithms and various optimization techniques, such as indexing the reference genome, parallel processing, and memory-mapping, to achieve fast and scalable alignment. Popular splice-aware aligners include STAR and HISAT2. The following step is typically the quantification, which involves estimating the abundance of genes or transcripts in the samples. The workflow involves the generation of a index from the reference genome and the annotation file (GFF/GTF). This index will be used by the quantification software to map aligned reads to annotated transcripts and quantify their expression levels. The resulting expression counts or abundance estimates represent the number of reads assigned to each transcript in the samples. Several tools are available to perform the quantification step, such as featureCounts, HTSeq, Salmon and RSEM. The alignment and the quantification steps can be also performed with lightweight alignment tools, which include Kallisto, Sailfish and Salmon. These tools avoid a base-to-base alignment of reads providing quantification estimates faster than the classical splice-aware algorithms but with a high accuracy. The resulting estimates are commonly referred to as pseudocounts or abundance estimates, that can be later utilized for downstream analysis. An example showing the differences between a reference-based aligner (STAR) and a pseudoaligner (Salmon) are represented in the scheme below:</p> <p>The figure illustrates the two typical examples of alignment/lightweight alignment and quantification performed with two classical software, STAR and Salmon:</p> <p>1) The STAR seed finding process begins by searching for the longest continuous portions of the reads that exactly match one location of the reference genome (Maximal Mappable Prefix, MMP). The fragments of the reads that mapped separately are defined as seeds. If the reads comprise a splice junction (as shown in the example), the first seed will be mapped to a donor splice site. The MMP search is then applied to the unmapped portion of the read, which will be mapped to an acceptor splice site. The MMP search allows read alignment even in cases of mismatches and indels, utilizing the MMP as an anchor for the extension. If the extension procedure results in a poor genomic alignment (presence of library adapters or poor sequencing quality tails), the read is soft clipped. In the next step, the anchor alignments are selected, and all the alignments located within a user-defined genomic window around the anchors are stitched together to find the best linear alignment. STAR assigns scores to each alignment based on various factors, including the number of mismatches, the presence of splice junctions, and the overall quality of alignment. The stitched combination with the highest score will result in the best alignment of a read. Through this stitching procedure, even reads with a large number of mismatches, indels, and gaps can be aligned. Finally, gene expression levels can be quantified with different quantification tools like the ones cited above;</p> <p>2) Salmon begins by building a transcriptome index, which combines a suffix array for efficient substring matching and alignment with a hash table for rapid retrieval of transcript-specific information based on k-mer sequences. The index is constructed by concatenating all transcripts into a single string, separated by unique delimiters, and generating all possible suffixes in lexicographical order. Salmon then extracts k-mers from the transcriptome and reads, and uses a hash function to map each k-mer to a numerical index in the hash table. By querying the hash table, Salmon identifies candidate transcripts containing the k-mer sequences and quantifies their abundance. This approach enables fast and accurate lightweight alignment and quantification of RNA-seq reads.</p>"},{"location":"theory/#differential-expression-de-analysis","title":"Differential expression (DE) analysis","text":"<p>The next step in a typical RNA-seq workflow is the differential expression analysis. It is a statistical method to compare gene expression levels between different experimental conditions such disease vs. healthy (e.g., tumor tissue vs. healthy tissue), treatment vs control (e.g., sample treated with a specific stimulus, drug or compound vs untreated sample), tissue vs tissue (e.g., brain vs heart). The objective of differential expression analysis is to assess, for each gene, whether the observed differences in expression (counts) between groups are statistically significant, taking into account the variation observed within groups (replicates). Before delving into details, it is important to point out some common characteristics of RNA-seq data that are essential to take in account in the choiche of the statistical model to utilize:</p> <p>1) Low Counts and Long Right Tail: RNA-seq data often exhibit a large number of genes with low counts, indicating that many genes are expressed at very low levels across samples. Simultaneously, RNA-seq data exhibit a long right tail in their distribution due to the absence of an upper limit for gene expression levels. Consequently, some genes are expressed at high levels, resulting in a distribution where most genes have low to moderate expression levels, while a few genes have very high counts. This combination of many low-count genes and a few highly expressed genes presents challenges for differential expression analysis, introducing high variability and potential skewness into the data. Accurate statistical modeling must therefore account for this distribution to avoid misleading conclusions;</p> <p></p> <p>2) Overdispersion: RNA-seq data are characterized by overdispersion, where the variance in gene expression levels often exceeds the mean (variance &gt; mean). In typical RNA-seq experiments, this variability is not constant and can be much higher than expected under a Poisson distribution, which assumes that the mean equals the variance (mean = variance). Overdispersion in RNA-seq data stems from biological variability, technical noise, and variations in sequencing depth across samples. Effective modeling of RNA-seq data requires statistical methods capable of handling this additional variability. The negative binomial distribution, which generalizes the Poisson distribution, addresses overdispersion by introducing an additional parameter, the dispersion parameter. This parameter allows the negative binomial distribution to capture the excess variability present in RNA-seq data, providing a more flexible and realistic representation compared to the Poisson distribution. </p> <p></p> <p>To model counts data with robust statistical methods, there are different software that have been developed. This part of the analysis is typically performed in R utilizing different packages such as [DESeq2] (https://bioconductor.org/packages/release/bioc/html/DESeq2.html), edgeR and limma. This tutorial focuses on DESeq2, a popular R package known for its robustness. The typical workflow is outlined in the flowchart below. For more detailed information and details refer to the DESeq2 vignette.</p> <p>Differential expression analysis is composed by different key steps:</p> <ul> <li> <p>Input data: the analysis starts with a matrix obtained in the alignment and quantification step that summarizes the expression levels of the different genes in each sample of the dataset. The rows of the matrix typically correspond to genes and the columns represent the samples. Each position of the matrix contains an integer value representing the number of reads associated to a particular gene in a specific sample. Another essential prerequisite is a metadata table describing the samples;</p> </li> <li> <p>Normalization: since differential expression analysis tools compare counts between sample groups for the same gene, they do not need to account for gene length. However, it is crucial to account for sequencing depth and RNA composition. DESeq2 addresses these factors using size factors, which correct for variations in library sizes and RNA composition across samples. Specifically, DESeq2 calculates size factors (in general a number aroun 1) using the \"median ratio\" method. This involves calculating the geometric mean of each gene's counts across all samples (row-wise geometric mean), dividing each gene's count by the geometric mean, and then taking the median of these ratios for each sample (column-wise). Finally each raw count is dived by the normalization factor to generate normalized counts. The median ratio method assumes that not all genes are differentially expressed. Large outlier genes will not disproportionately influence the median ratio values. This approach is robust to imbalances in up-/down-regulation and can handle large numbers of differentially expressed genes. By minimizing the impact of library size differences and accounting for RNA composition, this method ensures that expression levels are comparable across samples. It is important to understand that DESeq2 does not directly use normalized counts for the actual analysis. Instead, it utilizes raw counts and incorporates the normalization process within the Generalized Linear Model (GLM). While these normalized counts are beneficial for downstream visualization of results, they should not be used as input for DESeq2 or any other differential expression analysis tools that rely on the negative binomial model;</p> </li> <li> <p>Quality Control (QC): Ensuring the quality of RNA-seq data before proceeding with differential expression analysis is crucial. DESeq2 provides tools for quality control, including Principal Component Analysis (PCA) and hierarchical clustering. PCA is used to reduce the dimensionality of the data, allowing visualization of the samples in a lower-dimensional space. On the other hand, hierarchical clustering displays the correlation of gene expression for all pairwise combinations of samples in the dataset. These methods can reveal group of samples that behave similarly and can highlight potential outliers or unexpected sample patterns. For these quality control steps, DESeq2 typically uses variance-stabilized (vst) counts or regularized log-transformed (rlog) counts. RNA-seq count data follow a discrete distribution which is not suitable for many statistical and machine learning algorithms that assume continuous distributions. These transformations stabilize the variance across the range of mean values. This means that genes with low expression and genes with high expression will have variances that are more comparable to each other after transformation. These transformed counts are used to ensure that the quality control analyses are robust and informative, aiding in the detection of any issues that could affect the downstream differential expression analysis. Finally, prior to differential expression analysis, it is beneficial to filter out genes that are unlikely to be detected as differentially expressed. This filtering enhances the sensitivity to detect truly differentially expressed genes. These include genes with zero counts across all samples, genes with extreme count outliers, and genes with consistently low mean normalized counts across samples;</p> </li> <li> <p>Differential expression analysis with DESeq2: the process begins by modeling the raw counts, where normalization factors (also known as size factors) are applied to adjust for differences in library depth between samples. Next, DESeq2 estimates gene-wise dispersions and then shrinks these estimates to produce more accurate and reliable dispersion values, which are used to model the count data. The final steps involve fitting a negative binomial model to the data and performing hypothesis testing using either the Wald test or Likelihood Ratio Test to identify differentially expressed genes. So we can sum-up the different steps:</p> </li> </ul> <p>1) Estimate the size factors (normalization of the raw counts described above);</p> <p>2) Estimate gene-wise dispersion: to quantify dispersion DESeq2 utilizes the dispersion parameter (\u03b1) is closely tied to the mean (\u03bc) and variance of the data, as described by the equation Var = \u03bc + \u03b1 * \u03bc^2. This relationship has important implications: for genes with moderate to high count values, the square root of dispersion is equivalent to the coefficient of variation (Var / \u03bc), which represents the relative variability around the mean. A key feature of DESeq2's dispersion estimates is that they are negatively correlated with the mean and positively correlated with variance, resulting in higher dispersion values for genes with low expression levels and lower dispersion values for genes with high expression levels. In addition, genes with the same mean expression levels can exhibit different dispersion estimates based on their variance. To refine these estimates, DESeq2 shares information from genes with similar expression profiles, assuming that they exhibit similar dispersion patterns. By doing so, DESeq2 generates more accurate estimates of variation that are specifically tailored to the mean expression level of each gene;</p> <p>3) Fit curve to gene-wise dispersion estimates: this process, known as dispersion fitting, aims to model the relationship between the mean expression level of a gene and its dispersion. By doing so, DESeq2 can identify a trend in the dispersion estimates across genes, which is essential for accurate variance estimation. The fitted curve, typically a smooth curve, describes how dispersion changes as a function of the mean expression level;</p> <p>4) Shrink gene-wise dispersion estimates: the gene-wise dispersion estimates are shrunk towards the fitted curve, a process known as shrinkage. By pooling information across genes, DESeq2 can generate more accurate and reliable estimates of dispersion, even for genes with limited sample sizes or noisy data. The shrinkage step adjusts the gene-wise dispersion estimates, moving them closer to the fitted curve, which represents the average dispersion pattern across all genes. This adjustment helps to reduce the variability and noise associated with individual gene-wise estimates, resulting in more robust and consistent dispersion values. However, genes with exceptionally high dispersion values are not shrinked because they probably deviate from the modelling assumption, exhibiting elevated variability due to biological or technical factors. Shrinking these values could lead to false positives. By shrinking the dispersion estimates, DESeq2 can improve the accuracy of downstream analyses and reduce the number of false positives;</p> <p>5) Generalized Linear Model (GLM), Wald test and multiple test: DESeq2 fits a generalized linear model (GLM) to the count data for each gene, using a negative binomial distribution to account for overdispersion (variance &gt; mean). The GLM fit is then used to perform hypothesis testing for differential expression using the Wald test. The Wald test is a statistical test that evaluates the significance of the regression coefficients in the GLM, and is used to determine whether the gene is differentially expressed between conditions. However, when performing multiple tests, such as in the case of RNA-seq data where thousands of genes are tested, the risk of false positives increases. To account for this, DESeq2 employs multiple test correction methods (Benjamini-Hochberg procedure is the default) to adjust the p-values and control the false discovery rate (FDR). For example by setting the FDR cutoff to &lt; 0.05, 5% of genes identified as differentially expressed are expected to be false positive. For instance, if 400 genes are identified as differentially expressed with an FDR cutoff of 0.05, you would expect 20 of them to be false positives. This ensures that the results are truly significant and biologically relevant. By combining the GLM, Wald test, and multiple test correction, DESeq2 provides a powerful and accurate approach for identifying differentially expressed genes in RNA-seq data.</p> <p>After identifying differentially expressed genes using DESeq2, the next step is to interpret the biological significance of these genes through functional analysis. This involves examining the roles of the differentially expressed genes in various biological processes, pathways, and molecular functions, providing insights into the underlying mechanisms driving the observed changes in gene expression. By integrating the results from DESeq2 with functional analysis, researchers can gain a deeper understanding of the biological context and potential impact of the differential expression, leading to more informed hypotheses and further experimental validation. Different tools are available to carry out these functional analyses such as Gene Ontology, Reactome, KEGG, clusterProfiler, g:Profiler, and WikiPathways.</p>"}]}