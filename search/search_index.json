{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"nf-core/rnaseq tutorial","text":""},{"location":"#welcome","title":"Welcome","text":"<p>These pages are a tutorial workshop for the Nextflow pipeline nf-core/rnaseq.</p> <p>In this workshop, we will recap the application of next generation sequencing to identify differentially expressed genes. You will learn how to use the rnaseq pipeline to carry out this data-intensive workflow efficiently. We will cover topics such as configuration of the pipeline, code execution and data interpretation.</p> <p>Please note that this is not an introductory workshop, and we will assume some basic familiarity with Nextflow.</p> <p>By the end of this workshop, you will be able to:</p> <ul> <li>analyse simple NGS datasets with the nf-core/rnaseq workflow</li> <li>understand the key concepts behind RNAseq differential expression analysis</li> <li>customise some of its features for your own analyses</li> <li>integrate different sources of information to interpret the results</li> </ul> <p>Let's get started!</p>"},{"location":"#running-with-gitpod","title":"Running with Gitpod","text":"<p>In order to run this using GitPod, please make sure:</p> <ol> <li>You have a GitHub account: if not, create one here</li> <li>Once you have a GitHub account, sign up for GitPod using your GitHub user here choosing \"continue with GitHub\".</li> </ol> <p>Now you're all set and can use the following button to launch the service:</p> <p></p>"},{"location":"#additional-documentation","title":"Additional documentation","text":"<ul> <li>You can find detailed documentation on Nextflow here</li> <li>You can find additional training on these pages</li> </ul>"},{"location":"#credits-copyright","title":"Credits &amp; Copyright","text":"<p>This training material has been written and completed by Lorenzo Sola, Francesco Lescai and Mariangela Santorsola during the nf-core Hackathon in Barcellona, 2024. Thank you to Victoria Cepeda for her contributions to the tutorial's revision. The tutorial is aimed at anyone who is interested in using nf-core pipelines for their studies or research activities.</p> <p>The Docker image and Gitpod environment used in this repository have been created by Seqera but have been made open-source (CC BY-NC-ND) for the community.</p> <p>All examples and descriptions are licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.</p>"},{"location":"de_rstudio/","title":"Differential Analysis with DESeq2","text":"<p>In this section of the tutorial, we will guide you through the practical steps necessary to set up the RStudio environment, load the required libraries and data, and execute the DESeq2 analysis. By the end of this section, you will have a fully functional DESeq2 analysis pipeline set up in RStudio, ready to uncover the differentially expressed genes in your dataset.</p>"},{"location":"de_rstudio/#launching-the-rstudio-environment","title":"Launching the RStudio environment","text":"<p>Once the nf-core/rnaseq pipeline is terminated, the resulting data are stored in the folder <code>results_star_salmon</code>. Now, we can analyse the results by running DESeq2 on RStudio. First of all, we need to launch it:</p> <pre><code>sudo rstudio-server start\n</code></pre> <p>A pop-up will appear and by clicking on Open, we will be redirected to the RStudio login page. By inserting the username and the password reported below, we will be able to connect to RStudio:</p> <pre><code>Username: gitpod\nPassword: pass\n</code></pre> <p>To prevent losing connection, go back to gitpod and type on the Terminal:</p> <pre><code>sleep 2h\n</code></pre> <p>This command will keep the gitpod session active for exactly 2 hours, providing sufficient time to complete our analysis without interruption.</p> <p>Now come back to our RStudio session.</p>"},{"location":"de_rstudio/#differential-expression-analysis","title":"Differential Expression Analysis","text":"<p>As in all analysis, firstly we need to create a new project:</p> <p>1) Go to the File menu and select New Project;</p> <p>2) Select New Directory, New Project, name the project as shown below and click on Create Project;</p> <p></p> <p>3) The new project will be automatically opened in RStudio</p> <p>We can check whether we are in the correct working directory with <code>getwd()</code> The path <code>/workspace/gitpod/training/DE_analysis/</code> should appear on your console. To store our results in an organized way, we will create a folder named de_results using the New Folder button in the bottom right panel. We will save all our resulting tables and plots in this folder. Next, go to the File menu, select New File and then R Script to create a script editor in which we will save all commands required for the analysis. In the editor type:</p> <pre><code>#### Differential expression analysis with DESeq2 ####\n</code></pre> <p>and save the file as de_script.R. From now on, each command described in the tutorial can be added to your script. The resulting working directory should look like this:</p> <p></p> <p>The analysis requires several R packages. To utilise them, we need to load the following libraries:</p> <pre><code>#### Loading libraries ####\n\n# tidyverse: collection of R packages for data manipulation, visualization and modeling\n\nlibrary(\"tidyverse\")\n\n# DESeq2: package for differential gene expression analysis\n\nlibrary(\"DESeq2\")\n\n# pheatmap: package for creating heatmaps, which will be used to visualise the results\n\ninstall.packages(\"pheatmap\") # To install the package missing in the current RStudio env\n\nlibrary(\"pheatmap\")\n\n# RColorBrewer: package for creating color palettes, which will be used to customise the heatmaps\n\nlibrary(\"RColorBrewer\")\n\n# ggrepel: package that provides geoms for ggplot2 to repel overlapping text labels in the plots\n\nlibrary(\"ggrepel\")\n</code></pre> <p>and the pre-computed DESeq2 object (<code>dds</code>) generated by the nfcore/rnaseq pipeline:</p> <pre><code>#### Import the dds obtained from nfcore/rnaseq ####\n\nload(\"/workspace/gitpod/training/results_star_salmon/star_salmon/deseq2_qc/deseq2.dds.RData\")\n</code></pre> <p>In this tutorial we will analyse the <code>dds</code> object generated by running the alignment with STAR and the quantification with Salmon. Alternatively, a user could choose to analyse the the <code>dds</code> object generated by running only Salmon for both lightweight alignment and quantification. The file is stored in <code>/workspace/gitpod/training/results_star_salmon/salmon/deseq2_qc/deseq2.dds.RData</code>.</p> <p>In DESEq2, the <code>dds</code> object is a central data structure that contains the following components:  - <code>countData</code>: a matrix of raw count data, where each row represents a gene and each column represents a sample; - <code>colData</code>: a data frame containing information about the samples, such as the experimental design, treatment and other relevant metadata; - <code>design</code>: a formula specifying the experimental design utilised to estimate the dispersion and the log2foldchange.</p> <p>All these components can be checked with specific commands:</p> <pre><code>#### dds inspection ####\n\nhead(counts(dds)) # to check the raw counts\n\ncolData(dds) # to check the sample info\n\ndesign(dds) # to check the design formula\n</code></pre> <p>The <code>colData</code> and the <code>design</code> are the ones created within the nfcore/rnaseq pipeline and must be reorganised prior to the analysis. With the following commands we will create our metadata starting from the info stored in the <code>dds</code>. We will rename the column of the <code>colData</code>, we will ensure that the rownames of the metadata are present in the same order as the column names and finally we will update the <code>colData</code> of the <code>dds</code> object with our newly created metadata. </p> <pre><code>#### Creation of metadata starting from the dds colData ####\n\nmetadata &lt;- DataFrame(\n    sample = colData(dds)$sample,\n    condition = colData(dds)$Group1,\n    replica = colData(dds)$Group2\n)\n\n# Assign names to rows of metadata\n\nrownames(metadata) &lt;- colnames(counts(dds))\n\n# Fill the dds colData with the generated metadata\n\ncolData(dds) &lt;- metadata\n</code></pre> <p>Note</p> <p>With this operation we also eliminate the <code>sizeFactors</code> already estimated by the nfcore DESeq2 module.</p> <p>To avoid errors in DESeq2 is essential to check that sample names match between the <code>colData</code> and the <code>countData</code>, and that the sample are in the correct order:</p> <pre><code>#### Check that sample names match in both files ####\n\nall(colnames(dds$counts) %in% rownames(metadata)) # Must be TRUE\n\nall(colnames(dds$counts) == rownames(metadata)) # Must be TRUE\n</code></pre> <p>Now that everything is setted up, we can proceed to generate a new DESeq2 object with the corrected metadata and the right design:</p> <pre><code>#### Creation of a new dds ####\n\ndds_new  &lt;- DESeqDataSet(dds, design = ~ condition)\n\n# dds inspection \n\nhead(counts(dds_new)) # to check the raw counts\n\ncolData(dds_new) # to check the sample info\n\ndesign(dds_new) # to check the design formula\n</code></pre> <p>Comparing the structure of the newly created dds (<code>dds_new</code>) with the one automatically produced by the pipeline (<code>dds</code>), we can observe the differences:</p> <p></p> <p>Before running the different steps of the analysis, a good practice consists in pre-filtering the genes to remove those with very low counts. This is useful to improve computional efficiency and enhance interpretability. In general, it is reasonable to keep only genes with a sum counts of at least 10 for a minimal number of 3 samples:</p> <pre><code>#### Pre-filtering ####\n\n# Select a minimal number of samples = 3\n\nsmallestGroupSize &lt;- 3 \n\n# Select genes with a sum counts of at least 10 in 3 samples\n\nkeep &lt;- rowSums(counts(dds_new) &gt;= 10) &gt;= smallestGroupSize \n\n# Keep only the genes that pass the threshold\n\ndds_filtered &lt;- dds_new[keep,] \n</code></pre> <p>Now, it is time to run the differential expression analysis with the <code>DESeq()</code> function:</p> <pre><code>#### Run the DESeq2 analysis ####\n\ndds_final &lt;- DESeq(dds_filtered)\n</code></pre> <p>The <code>DESeq()</code> function is a high-level wrapper that simplifies the process of differential expression analysis by combining multiple steps into a single function call.</p> <p>This makes the workflow more user-friendly and ensures that all necessary preprocessing and statistical steps are executed in the correct order. The key functions that DESeq2 calls include:  - estimateSizeFactors: to normalise the count data; - estimateDispersion: to estimate the dispersion; - nbinomWaldTest: to perform differential expression test.</p> <p>The individual functions can be carried out also singularly as shown below:</p> <pre><code>#### Differential expression analysis step-by-step ####\n\ndds_final &lt;- estimateSizeFactors(dds_filtered)\n\ndds_final &lt;- estimateDispersions(dds_final)\n\ndds_final &lt;- nbinomWaldTest(dds_final)\n</code></pre> <p>The next step in the DESeq2 workflow is to perform quality control (QC) analysis on our data. This analysis is crucial for identifying potential issues or biases and ensuring the data are suitable for downstream analysis. For QC analysis, it is useful to work with transformed versions of the count data, <code>variance stabilizing transformations (vst)</code> and <code>regularized logarithm (rlog)</code>. While, the rlog is more robust to outliers and extreme values, vst is computationally faster and so preferred for larger dataset. Notice that these transformations are used for visualisation purposes, while DESeq2 requires raw counts for differential expression analysis.</p> <pre><code>#### Transform normalised counts for data visualisation ####\n# A user can choose among vst and rlog. In this tutorial we will work with rlog transformed data.\n\nrld &lt;- rlog(dds_final, blind = TRUE)\n</code></pre> <p>The <code>rlog</code> and the <code>vst</code> transformations have an argument, blind that can be set to: - TRUE (default): useful for QC analysis because it re-estimates the dispersion, allowing for comparison of samples in an unbiased manner with respect to experimental conditions; - FALSE: the function utilizes the already estimated dispersion, generally applied when differences in counts are expected to be due to the experimental design.</p> <p>Next, we perform Principal Component Analysis (PCA) to explore the data. DESeq2 provides a built-in function, <code>plotPCA()</code>, which uses ggplot2 for visualisation, taking the <code>rld</code> (or the <code>vst</code>) object as input. Since the treatment is the principal condition of interest in our metadata, we will use the <code>condition</code> information from our metadata to plot the PCA: </p> <pre><code>#### Plot PCA ####\n\nplotPCA(rld, intgroup = \"condition\")\n</code></pre> <p>The second essential step in QC analysis is hierarchical clustering. Although DESeq2 does not have a built-in function for this analysis, we can use the <code>pheatmap()</code> function from the pheatmap package. We will extract the matrix of rlog-transformed counts from the <code>rld</code> object (pheatmap input), compute pairwise correlations and plot the heatmap:</p> <pre><code>#### Plot sample to sample distance (hierarchical clustering) ####\n\n# Extract the matrix of rlog-transformed counts from the rld object\n\nsampleDists &lt;- dist(t(assay(rld)))  # Calculate pairwise distances between samples using the dist() function with Euclidean distance as the default method. By transposing the matrix with t(), we ensure that samples become rows and genes become columns, so that the dist function computes pairwise distances between samples.\n\n# Convert distances to a matrix\n\nsampleDistMatrix &lt;- as.matrix(sampleDists)  \n\n# Set the row and column names of the distance matrix\n\nrownames(sampleDistMatrix) &lt;- paste(rld$condition, rld$replica, sep = \"_\")\n\ncolnames(sampleDistMatrix) &lt;- paste(rld$condition, rld$replica, sep = \"_\")\n\n# Define a color palette for the heatmap\n\ncolors &lt;- colorRampPalette(rev(brewer.pal(9, \"Greens\")))(255) # function from RColorBrewer package\n\n# Create the heatmap\n\npheatmap(sampleDistMatrix, \n        clustering_distance_rows = sampleDists, \n        clustering_distance_cols = sampleDists, \n        col = colors, \n        fontsize_col = 8, \n        fontsize_row = 8)\n</code></pre> <p>The normalised counts stored in the <code>dds</code> can be inspected with the <code>counts()</code> function and saved in our results folder:</p> <pre><code>#### Inspect the normalised counts ####\n\n# Display the first few rows of the normalised counts to inspect the data\n\nhead(counts(dds_final, normalized = TRUE))\n\n# Display the first few rows of the raw counts (not normalised) to compare with the normalised counts\n\nhead(counts(dds_final))\n\n# Convert the normalised counts from the DESeq2 object to a tibble\n\nnormalised_counts &lt;- as_tibble(counts(dds_final, normalized = TRUE))\n\n# Add a column for gene names to the normalised counts tibble\n\nnormalised_counts$gene &lt;- rownames(counts(dds_final))\n\n# Relocate the gene column to the first position\n\nnormalised_counts &lt;- normalised_counts %&gt;% \n  relocate(gene, .before = control_rep1)\n\n# Save normalised counts \n\nwrite.csv(normalised_counts, file = \"de_results/normalised_counts.csv\")\n</code></pre> <p>The <code>results()</code> function in DESeq2 is used to extract the results of the DE analysis. This function takes the <code>dds</code> object as input and returns a DataFrame containing the results of the analysis:</p> <ul> <li>baseMean: the average expression level of the gene across all samples;</li> <li>log2FoldChange: the log2 fold change of the gene between the condition of interest and the reference level;</li> <li>lfcSE: the standard error of the log2 fold change;</li> <li>stat: the Wald statistic, which is used to calculate the p-value;</li> <li>pvalue: the p-value from the Wald test indicates the probability of observing the measured difference in gene expression (log2 fold change) by chance, assuming no true difference exists (null hypothesis). A low p-value suggests that the observed expression change between samples is unlikely due to random chance, so we can reject the null hypothesis;</li> <li>padj: the adjusted p-value, which takes into account multiple testing corrections, using the Benjamini-Hochberg method to control the false discovery rate;</li> </ul> <p>By default, the <code>results()</code> function returns the results for all genes in the analysis with an adjusted p-value below a specific FDR cutoff, set by default to 0.1. This threshold can be modified with the parameter <code>alpha</code>. The <code>results()</code> function can also be customised to filter the results based on certain criteria (log2 fold change or padj) or to set a specific contrast. A contrast is a specific comparison between two or more levels of a factor, such as the comparison between the treatment and control groups. The order of the contrast names determines the direction of the fold change that is reported in the results. Specifically, the first level of the contrast is the condition of interest and the second level is the reference level.  Notice that in this tutorial the contrast is already correctly specified.</p> <pre><code>#### Extract results table from the dds object ####\n\nres &lt;- results(dds_final)\n\n# Visualise the results\n\nhead(res) \n\n# Summarise the results showing the number of tested genes (genes with non-zero total read count), the genes up- and down-regulated at the selected threshold (alpha) and the number of genes excluded by the multiple testing due to a low mean count \n\nsummary(res)\n\n# DESeq2 function to extract the name of the contrast\n\nresultsNames(dds_final) \n\n# res &lt;- results(dds, contrast = c(\"design_formula\", \"condition_of_interest\", \"reference_condition\"))\n# Command to set the contrast, if necessary\n\n# Store the res object inside another variable because the original res file will be required for other functions\n\nres_viz &lt;- res\n\n# Add gene names as a new column to the results table\n\nres_viz$gene &lt;- rownames(res)\n\n# Convert the results to a tibble for easier manipulation and relocate the gene column to the first position\n\nres_viz &lt;- as_tibble(res_viz) %&gt;% \n  relocate(gene, .before = baseMean)\n\n# Save the results table \n\nwrite.csv(res_viz, file = \"de_results/de_result_table.csv\")\n</code></pre> <p>In the Experimental Design section, we emphasised the importance of estimating the log2 fold change threshold using a statistical power calculation, rather than selecting it arbitrarily. This approach ensures that the chosen threshold is statistically appropriate and tailored to the specifics of the experiment. However, since we are working with simulated data for demonstration purposes, we will use a padj threshold of 0.05 and consider genes with a log2 fold change greater than 1 or lower than -1 as differentially expressed.</p> <pre><code>#### Extract significant DE genes from the results ####\n\n# Filter the results to include only significantly differentially expressed genes with an adjusted p-value (padj) less than 0.05 and a log2foldchange greater than 1 or less than -1\n\nresSig &lt;- subset(res_viz, padj &lt; 0.05 &amp; abs(log2FoldChange) &gt; 1) \n\n# Convert the results to a tibble for easier manipulation and relocate the 'Gene' column to be the first column\n\nresSig &lt;- as_tibble(resSig) %&gt;% \n  relocate(gene, .before = baseMean) \n\n# Order the significant genes by their adjusted p-value (padj) in ascending order\n\nresSig &lt;- resSig[order(resSig$padj),] \n\n# Display the final results table of significant genes\n\nresSig \n\n# Save the significant DE genes \n\nwrite.csv(resSig, file = \"de_results/sig_de_genes.csv\")\n</code></pre> <p>Now that we have obtained the results of the differential expression analysis, it's time to visualise the data to gain a deeper understanding of the biological processes that are affected by the experimental conditions. Visualisation is a crucial step in RNA-seq analysis, as it allows us to identify patterns and trends in the data that may not be immediately apparent from the numerical results. In the following sections, we will explore different types of plots that are commonly used to visualise the results of RNA-seq analysis, including:</p> <ul> <li>MA plot: it is a type of scatter plot that is commonly used to visualise the results of differential expression analysis for all the samples. The plot displays the mean of the normalised counts on the x-axis and the log2 fold change on the y-axis. This allows the visualisation of the relationship between the magnitude of the fold change and the mean expression level of the genes. Genes that are highly differentially expressed will appear farthest from the horizontal line, while genes with low expression levels will appear closer to the line. The MA plot is useful for identifying genes that are both highly expressed and highly differentially expressed between two conditions.</li> </ul> <pre><code>#### MA plot ####\n\nplotMA(res, ylim = c(-2,2))\n</code></pre> <ul> <li>counts plot: it plots the normalised counts for a single gene across the different conditions in your experiment. It\u2019s particularly useful for visualising the expression levels of specific genes of interest and comparing them across sample groups.</li> </ul> <pre><code>#### Plot a specific gene in this case ENSG00000142192, a DE gene ####\n\nplotCounts(dds_final, gene = \"ENSG00000142192\")\n</code></pre> <p>heatmap: plot of the normalised counts for all the significant genes obtained with the <code>pheatmap()</code> function. The heatmap provides insights into genes and sample relationships that may not be apparent from individual gene plots alone. Notiche that this plot is based on the normalised counts.</p> <pre><code>#### Heatmap ####\n\n# Extract only the first column (gene names) from the result object containing the significant genes\n\nsignificant_genes &lt;- resSig[, 1]\n\n# Extract normalised counts for significant genes from the normalised counts matrix and convert the \"gene\" column to row names \n\nsignificant_counts &lt;- inner_join(normalised_counts, significant_genes, by = \"gene\") %&gt;% \n  column_to_rownames(\"gene\")\n\n# Create the heatmap using pheatmap\n\npheatmap(significant_counts, \n         cluster_rows = TRUE,\n         fontsize = 8,\n         scale = \"row\",\n         fontsize_row = 8,\n         height = 10)\n</code></pre> <ul> <li>volcano plot: it is a type of scatter plot that displays the log2 fold change on the x-axis and the log transformed padj on the y-axis. This allows for the visualisation of both the magnitude and significance of the changes in gene expression between two conditions. Genes that are highly differentially expressed (i.e., have a large log2 fold change) and are statistically significant (i.e., have a low padj) will appear in the top-left or top-right corners of the plot making easier to identify the most biologically meaningful changes.</li> </ul> <pre><code>#### Volcano plot ####\n\n# Convert the results to a tibble and add a column indicating differential expression status\n\nres_tb &lt;- as_tibble(res) %&gt;% \n  mutate(diffexpressed = case_when(\n    log2FoldChange &gt; 1 &amp; padj &lt; 0.05 ~ 'upregulated', \n    log2FoldChange &lt; -1 &amp; padj &lt; 0.05 ~ 'downregulated',\n    TRUE ~ 'not_de'))\n\n# Add a new column with gene names\n\nres_tb$gene &lt;- rownames(res) \n\n# Relocate the 'gene' column to be the first column\n\nres_tb &lt;-  res_tb %&gt;% \n  relocate(gene, .before = baseMean)\n\n# Order the table by adjusted p-value (padj) and add a new column for gene labels\n\nres_tb &lt;- res_tb %&gt;% arrange(padj) %&gt;% \n  mutate(genelabels = \"\")\n\n# Label the top 5 most significant genes\n\nres_tb$genelabels[1:5] &lt;- res_tb$gene[1:5]\n\n# Create a volcano plot using ggplot2\n\nggplot(data = res_tb, aes(x = log2FoldChange, y = -log10(padj), col = diffexpressed)) + \n  geom_point(size = 0.6) + \n  geom_text_repel(aes(label = genelabels), size = 2.5, max.overlaps = Inf) +\n  ggtitle(\"DE genes treatment versus control\") + \n  geom_vline(xintercept = c(-1, 1), col = \"black\", linetype = 'dashed', linewidth = 0.2) +\n  geom_hline(yintercept = -log10(0.05), col = \"black\", linetype = 'dashed', linewidth = 0.2) +\n  theme(plot.title = element_text(size = rel(1.25), hjust = 0.5),\n        axis.title = element_text(size = rel(1))) +\n  scale_color_manual(values = c(\"upregulated\" = \"red\", \n                                \"downregulated\" = \"blue\", \n                                \"not_de\" = \"grey\")) +\n  labs(color = 'DE genes') +\n  xlim(-3,5)\n</code></pre>"},{"location":"de_rstudio/#functional-analysis","title":"Functional analysis","text":"<p>The output of the differential expression analysis is a list of significant DE genes. To uncover the underlying biological mechanisms, various downstream analyses can be performed, such as functional enrichment analysis (identify overrepresented biological processes, molecular functions, cellular components or pathways) and network analysis (group genes based on similar expression patterns to identify novel interactions). To facilitate the interpretation of the resulting list of DE genes, a range of freely available web- and R-based tools can be employed.</p> <p>In this tutorial, we will explore an enrichment analysis technique known as Over-Representation Analysis (ORA), a powerful tool for identifying biological pathways or processes that are significantly enriched with DE genes. The underlying statistic behind ORA is the hypergeometric test, which considers three key components:</p> <ul> <li>Universe: the background list of genes (for example the genes annotated in a genome);</li> <li>Gene Set: a subset of genes known to be involved in a specific biological pathway or process (for example genes from the Gene Ontology database);</li> <li>Gene List: the number of DE genes.</li> </ul> <p>The hypergeometric test calculates the probability of observing a certain number of genes from the gene set (pathway or process) within the gene list (DE genes) by chance. An important aspect of this analysis is the concept of membership. It defines the relationship between DE genes and genes from the analysed gene set. By knowing which genes belong to which pathways/processes, we can determine whether the observed overlap between DE genes and a particular pathway/process is greater than what would be expected by random chance.</p> <pre><code>#### Enrichment analysis (ORA) ####\n\n# Loading libraries\n\n# clusterProfiler: package for enrichment analysis\n\nlibrary(clusterProfiler)\n\n# org.Hs.eg.db: package for the human gene annotation database\n\nlibrary(org.Hs.eg.db)\n\n# cowplot: package for combining multiple plots\n\ninstall.packages(\"cowplot\") # To install the package missing in the current RStudio env\n\nlibrary(cowplot)\n\n# Prepare gene list\n# Extract the log2 fold change values from the results data frame\n\ngene_list &lt;- res$log2FoldChange\n\n# Name the vector with the corresponding gene identifiers\n\nnames(gene_list) &lt;- res$gene\n\n# Sort the list in decreasing order (required for clusterProfiler)\n\ngene_list &lt;- sort(gene_list, decreasing = TRUE)\n\n# Extract the significantly differentially expressed genes from the results data frame\n\nres_genes &lt;- resSig$gene\n\n# Run GO enrichment analysis using the enrichGO function\n\ngo_enrich &lt;- enrichGO(\n  gene = res_genes,                # Genes of interest\n  universe = names(gene_list),     # Background gene set\n  OrgDb = org.Hs.eg.db,            # Annotation database\n  keyType = 'ENSEMBL',             # Key type for gene identifiers\n  readable = TRUE,                 # Convert gene IDs to gene names\n  ont = \"ALL\",                     # Ontology: can be \"BP\", \"MF\", \"CC\", or \"ALL\"\n  pvalueCutoff = 0.05,             # P-value cutoff for significance\n  qvalueCutoff = 0.10              # Q-value cutoff for significance\n)\n\n# Create a bar plot of the top enriched GO terms\n\nbarplot &lt;- barplot(\n  go_enrich, \n  title = \"Enrichment analysis barplot\",\n  font.size = 8\n)\n\n# Create a dot plot of the top enriched GO terms\n\ndotplot &lt;- dotplot(\n  go_enrich,\n  title = \"Enrichment analysis dotplot\",\n  font.size = 8\n)\n\n# Combine the bar plot and dot plot into a single plot grid\n\nplot_grid(barplot, dotplot, nrow = 2)\n</code></pre>"},{"location":"interpretation/","title":"Interpretation","text":"<p>Once DE genes have been identified, the next crucial step is to interpret the results. This involves the inspection of tables and plots generated during the analysis to understand the biological significance of the data. In this part of the tutorial, we will delve into the results by discussing the significant DE genes and we will explore various plots generated during the analysis.</p> <p>Note</p> <p>The results illustrated in this section might show slight variations compared to your runs due to randomness in the STAR algorithm. This randomness arises from using variable seed values and parallel processing, leading to minor differences in results between runs on the same data. These small discrepancies are not biologically significant and may affect counts and subsequent plots (such as PCA and count plots). However, the overall patterns and main findings should remain consistent. While exact reproducibility is ideal, minor variations are acceptable in practice, as long as they do not impact the main conclusions of the study.</p>"},{"location":"interpretation/#quality-control-plots","title":"Quality control plots","text":"<p>The first plot we will examine is the Principal Component Analysis (PCA) plot. Since we're working with simulated data, our metadata is relatively simple, consisting of just three variables: sample, condition and replica. In a typical RNA-seq experiment, however, metadata can be complex and encompass a wide range of variables that could contribute to sample variation, such as sex, age and developmental stage. </p> <p></p> <p>By plotting the PCA on the PC1 and PC2 axes, using <code>condition</code> as the main variable of interest, we can quickly identify the primary source of variation in our data. By accounting for this variation in our design model, we should be able to detect more differentially expressed genes related to <code>condition</code>. When working with real data, it's often useful to plot the data using different variables to explore how much variation is explained by the first two PCs. Depending on the results, it may be informative to examine variation on additional PC axes, such as PC3 and PC4, to gain a more comprehensive understanding of the data.</p> <p>Next, we will examine the hierarchical clustering plot to explore the relationships between samples based on their gene expression profiles. The heatmap is organized such that samples with similar expression profiles are close to each other, allowing us to identify patterns in the data.</p> <p></p> <p>Remember that to create this plot, we utilized the <code>dist()</code> function, so in the legend on the right, a value of 0 corresponds to high correlation, while a value of 5 corresponds to very low correlation. Similar to PCA, we can see that samples tend to cluster together according to <code>condition</code>, indeed we can observe a high degree of correlation between the three control samples and between the three treated samples. </p> <p>Overall, the integration of these plots suggests that we are working with high-quality data and we can confidently proceed to the differential expression analysis.</p>"},{"location":"interpretation/#differential-expression-results","title":"Differential expression results","text":"<p>From this point, we will examine plots that are generated after the differential expression analysis. These plots are not quality control (QC) plots, but rather plots that help us to interpret the results.  After running the <code>results()</code> function, a good way to start to have an idea about the results is to look at the MA plot. </p> <p></p> <p>By default, genes are coloured in blue if the padj is less than 0.1 and the log2foldchange greater than or less than 0. Genes that fall outside the plotting region are represented as open triangles. Note that we have not yet applied a filter to select only significant, which we define as those with a padj value less than 0.5 and a log2 fold change of at least 1 or -1.</p> <p>After filtering our genes of interest according to our threshold, let's have a look to our significatnt genes:</p> <pre><code>gene                baseMean        log2FoldChange     lfcSE          stat            pvalue              padj\nENSG00000205726     121645.5908     2.894480           0.1515387      19.100600       2.496005e-81        5.840651e-79\nENSG00000142192     51065.3192      3.025489           0.1891258      15.997230       1.335883e-57        1.562983e-55\nENSG00000142156     20805.8078      2.977705           0.2159277      13.790287       2.915972e-43        2.274458e-41\nENSG00000159231     458.9277        -1.194777          0.3058100      -3.906926       9.347790e-05        5.468457e-03\nENSG00000156282     481.7624        1.095272           0.2969594      3.688289        2.257672e-04        1.056590e-02\n</code></pre> <p>To gain a comprehensive overview of the transcriptional profile, the volcano plot represents a highly informative tool.</p> <p></p> <p>The treatment induced differential expression in five genes, with one downregulated and four upregulated. This plot visually represents the numerical results reported in the table above.</p> <p>After the identification of DE genes, it's informative to visualise the expression of specific genes of interest. The <code>plotCounts()</code> function applied directly on the <code>dds</code> object allows us to examine individual gene expression profiles without accessing the full <code>res</code> object.</p> <p></p> <p>In our example, post-treatment, we observe a significant increase in the expression of the ENSG00000142192 gene, highlighting its responsiveness to the experimental conditions.</p> <p>Finally, we can create a heatmap using the normalised expression counts of DE genes. The resulting heatmap visualises how the expression of significant genes varies across samples. Each row represents a gene, and each column represents a sample. The color intensity in the heatmap reflects the normalised expression levels: red colors indicate higher expression, while blue colors indicate lower expression.</p> <p></p> <p>By examining the heatmap, we can visually identify the expression patterns of our five significant differentially expressed genes. This visualization allows us to identify how these genes respond to the treatment. The heatmap provides a clear and intuitive way to explore gene expression dynamics.</p>"},{"location":"interpretation/#over-representation-analysis-ora","title":"Over Representation Analysis (ORA)","text":"<p>Finally, we can attempt to assign biological significance to our differentially expressed genes through Enrichment Analysis (ORA). The ORA analysis identifies specific biological pathways, molecular functions and cellular processes, according to the Gene Ontology (GO) database, that are enriched within our differentially expressed genes. </p> <p></p> <p>The enrichment analysis reveals a possible involvement of cellular structures and processes, including \"clathrin-coated pit\", \"dendritic spine\", \"neuron spine\" and \"endoplasmic reticulum lumen\". These terms suggest a focus on cellular transport, structural integrity and protein processing, especially in neural contexts. This pattern points to pathways related to cellular organization and maintenance, possibly playing an important role in the biological condition under study.</p>"},{"location":"interpretation/#conclusions","title":"Conclusions","text":"<p>In this tutorial, we have walked through the steps of performing differential expression analysis using DESeq2, from preparing the data to interpreting the results. We have seen how to identify differentially expressed genes, visualise the results and perform enrichment analysis to gain insights into the biological significance of the results. By following this tutorial, you should now be able to perform differential expression analysis using DESeq2 and interpret the results in the context of your own research question.</p>"},{"location":"rnaseq/","title":"The nf-core/rnaseq pipeline","text":"<p>In order to carry out a RNA-Seq analysis we will use the nf-core pipeline rnaseq.</p>"},{"location":"rnaseq/#overview","title":"Overview","text":"<p>The pipeline is organised following the diffent blocks: pre-processing, alignment (or lightweight alignment) and quantification, post-processing and final QC.</p> <p></p> <p>In each process, the users can choose among a range of different options. Importantly, the users can decide to follow one of the two different routes in the alignment and quantification step: - alignment and quantification (stage 2); - pseudoalignment and quantification (stage 3). </p>"},{"location":"rnaseq/#experimental-design","title":"Experimental Design","text":"<p>The number of reads and the number of biological replicates are two critical factors that researchers need to carefully consider during the design of a RNA-seq experiment. While it may seem intuitive that having a large number of reads is always desirable, an excessive number can lead to unnecessary costs and computational burdens, without providing significant improvements in quality of the data. Instead, it is often more beneficial to prioritise the number of biological replicates, as it allows to capture the natural biological variation of the data. Biological replicates involve collecting and sequencing RNA from distinct biological samples (e.g., different individuals, tissues, or time points), helping to detect genuine changes in gene expression. </p> <p>Note</p> <p>This concept must not be confused with technical replicates that asses the technical variability of the sequencing platform by sequencing the same RNA sample multiple time.</p> <p>To obtain optimal results, it is crucial to balance the number of biological replicates and sequencing depth. While deeper sequencing improves the detection of lowly expressed genes, it reaches a plateau, beyond which no additional benefits are gained. Statistical power calculations can inform experimental design by estimating the optimal number of reads and replicates required. For instance, this approach helps establish a suitable log2 fold change (log2FC) threshold for  the DE analysis. By incorporating multiple biological replicates into the design and optimizing sequencing depth, researchers can enhance the statistical power of the analysis, reducing the number of false positive results and increasing the reliability of the findings.</p>"},{"location":"rnaseq/#library-design","title":"Library design","text":"<p>RNA-seq library design involves critical decisions, including the choice between paired-end and single-end sequencing. Paired-end sequencing provides valuable information on structural variations and transcript isoforms, improving mapping accuracy, especially for longer transcripts and repetitive regions. In contrast, single-end sequencing, where only one end of the fragment is sequenced, can be more cost-effective while still providing high-quality data for gene expression analysis. The decision between paired-end and single-end sequencing ultimately depends on the research question and experimental goals. Paired-end sequencing is preferred for novel transcript identification or isoform characterization, while single-end sequencing is sufficient for gene expression quantification. The type of RNA (e.g., mRNA or total RNA), read length, budget and computational resources can impact the choice.</p>"},{"location":"rnaseq/#reference-genome","title":"Reference genome","text":"<p>nf-core pipelines make use of the Illumina iGenomes collection as reference genomes. Before starting the analysis, the users might want to check whether the genome they need is part of this collection. They also might want to consider downloading the reference locally, when running on premises: this would be useful for multiple runs and to speed up the analysis. In this case the parameter <code>--igenomes_base</code> might be used to pass the root directory of the downloaded references. </p> <p>One might also need to use custom files: in this case the users might either provide specific parameters at command line (<code>--fasta</code> option followed by the genome of choiche), or create a config file adding a new section to the <code>genome</code> object. See here for more details.</p> <p>We will follow this specific approach in this tutorial, since the data we will be using have been simulated on chromosome 21 of the Human GRCh38 reference, and we have prepared genome fasta and genome index containing only this chromosome locally. The two files are <code>/workspace/gitpod/training/data/refs/Homo_sapiens_assembly38_chr21.fa</code> and <code>/workspace/gitpod/training/data/refs/Homo_sapiens_assembly38_chr21.fa.fai</code>, respectively.</p>"},{"location":"rnaseq/#reference-annoation","title":"Reference annoation","text":"<p>The reference annotation plays a crucial role in the RNA-seq analysis. Without a high-quality reference annotation, RNA-seq analysis would result in inaccurate or incomplete results. The reference annotation provides a precise guide for aligning sequencing reads to specific genomic regions, allowing to identify genes, transcripts and regulatory elements. This is particularly important for identifying novel transcripts and alternative splicing events.</p> <p>nf-core pipelines make use of the Illumina iGenomes collection also as reference annotation. The reference annotations are vastly out of date with respect to current annotations and miss certain features. So, the general recommendation is to download a newest annotation version compatible with the genome. A user can utilize the <code>--gtf</code> or the <code>--gff</code> options to specify the annottation files of choiche, or create a config file adding a new section to the <code>genome</code> object. </p> <p>Similarly to the approach utilised for the genome, in this tutorial we will follow this approach. The annotation files include only the annotated transcripts on chromosome 21 of the Human GRCh38 reference genome and we have already prepared these files locally. The two files are <code>/workspace/gitpod/training/data/refs/gencode_v29_chr21.gff</code> and <code>/workspace/gitpod/training/data/refs/gencode_v29_transcripts_chr21.fa</code>, respectively.</p>"},{"location":"rnaseq/#input-files","title":"Input files","text":"<p>The input data should be provided in a CSV file, according to a format that is largely common for nf-core pipelines. The format is described in the rnaseq usage page. In the tutorial, the input file is <code>/workspace/gitpod/training/data/reads/rnaseq_samplesheet.csv</code>.</p>"},{"location":"rnaseq/#running-nf-corernaseq","title":"Running nf-core/rnaseq","text":"<p>In the following sections we will: - prepare our references; - set our computational resources in order to be able to run the pipeline on a gitpod VM; - edit the optional settings; - run the pipeline.</p>"},{"location":"rnaseq/#reference-and-annotation-files","title":"Reference and annotation files","text":"<p>Following the considerations above, we will first of all edit the <code>nextflow.config</code> file in our working directory to add a new genome. It is sufficient to add the following code to the <code>parameters</code> directive in the config.</p> <pre><code>igenomes_base = '/workspace/gitpod/training/data/refs/'\ngenomes {\n        'GRCh38chr21' {\n            fasta                 = \"${params.igenomes_base}/sequence/Homo_sapiens_assembly38_chr21.fasta\"\n            fasta_fai             = \"${params.igenomes_base}/sequence/Homo_sapiens_assembly38_chr21.fasta.fai\"\n            gff                   = \"${params.igenomes_base}/gencode_v29_chr21_parsed.gff\"\n            transcript_fasta      = \"${params.igenomes_base}/gencode.v29.transcripts_chr21.fa\"\n            star_index            = \"${params.igenomes_base}/star_index_chr21.tar.gz\"\n            salmon_index          = \"${params.igenomes_base}/salmon_index_chr21.tar.gz\"\n    }\n}\n</code></pre> <p>To speed up the analysis we will include the <code>star_index</code> and the <code>salmon_index</code> in the config. These files have already been created locally.</p>"},{"location":"rnaseq/#computing-resources","title":"Computing resources","text":"<p>Based on the choices we made when starting up the gitpod environment, we recommend to use the following additional parameters. They can also be added to the parameters directive in the config file we just edited.</p> <pre><code>params {\n    max_cpus      = 2\n    max_memory    = '6.5GB'\n    max_time      = '2.h'\n}\n</code></pre>"},{"location":"rnaseq/#launching-the-pipeline","title":"Launching the pipeline","text":"<p>Now we are ready to launch the pipeline, and we can use the following command line:</p> <pre><code>nextflow run nf-core/rnaseq -r 3.12.0 \\\n--input /workspace/gitpod/training/data/reads/rnaseq_samplesheet.csv \\\n--outdir ./results_star_salmon \\\n--genome GRCh38chr21 \\\n--aligner star_salmon \\\n--pseudo_aligner salmon \\\n--skip_biotype_qc \\\n--skip_stringtie \\\n--skip_bigwig \\\n--skip_umi_extract \\\n--skip_trimming \\\n--skip_fastqc \\\n--skip_markduplicates \\\n--skip_dupradar \\\n--skip_rseqc \\\n--skip_qualimap\n</code></pre> <p>Notice that we will run the pipeline with STAR as aligner and Salmon in alignment-based mode to quantify gene expression. We will also run the pipeline with Salmon in mapping-based mode to perform a lightweight alignment and quantification. The <code>skip</code> parameters were inserted to reduce the running time.</p>"},{"location":"theory/","title":"RNAseq Analysis","text":"<p>Before we dive into the nf-core pipeline for analysing RNA-sequencing data, it's worth looking at some theoretical aspects of RNA-seq.</p>"},{"location":"theory/#overview","title":"Overview","text":"<p>Given the central role of RNA in a wide range of cellular and molecular functions, RNA-seq has emerged as a powerful tool for measuring the presence and levels of RNA species in biological samples. The technique is based on next-generation sequencing (NGS) technologies and is now considered the gold standard in the field of transcriptomics.</p> <p>After RNA extraction and reverse transcription into complementary DNA (cDNA), the biological material is sequenced, generating NGS \"reads\" that correspond to the RNA captured in a specific cell, tissue, or organ at a given time. The sequencing data is then bioinformatically processed through a typical workflow summarised in the diagram below:</p> <p></p> <p>In the scheme, we can identify three key phases in the workflow: data pre-processing, alignment and quantification, and differential expression analysis. In the data pre-processing step, the raw reads are processed to remove adapters and contaminants, and their quality is checked. Then, reads are mapped to a reference genome, and gene abundance is estimated. The workflow can also follow an alternative route based on lightweight alignment and quantification, reducing the time required for analysis. Finally, differentially expressed genes are identified using statistical tests, annotated, and visualised.</p> <p>Depending on the user's needs, the workflow can include additional downstream analyses such as functional enrichment analysis, co-expression analysis, and integration with other omics data.</p>"},{"location":"theory/#pre-processing","title":"Pre-processing","text":"<p>The pre-processing of sequencing reads from RNA-seq data is a critical step to ensure the quality and accuracy of downstream analysis. The raw reads obtained from the sequencer are stored as FASTQ files, which contain both the sequence data and quality scores. The initial processing step involves evaluating the quality of the reads and identifying potential issues such as adapter contamination, sequencing errors, or low-quality bases. The presence of adapters (short DNA sequences ligated to the ends of DNA fragments during library preparation) is detected through comparison with known adapter sequences or by using algorithms that identify adapter-like sequences, and removed in a process known as read trimming. Next, reads containing contaminants (genomic DNA and/or rRNA) and those with low-quality bases are filtered out. Finally, the quality of the filtered reads is checked again to ensure their suitability for downstream processing.</p>"},{"location":"theory/#alignment-or-lightweight-alignment-and-quantification","title":"Alignment (or lightweight alignment) and quantification","text":"<p>In the RNA-seq workflow, the alignment step involves mapping sequencing reads to a reference genome or transcriptome to determine the position and orientation of each read relative to the reference sequence.</p> <p>Errors, gaps, regions of poor sequence quality, insertions/deletions (INDELs), as well as duplicated and repetitive regions in the reference sequence, make this step challenging. Addressing these issues by choosing a high-quality reference and an appropriate aligner is essential for accurate results. A crucial component in the alignment step is the annotation file, which can be in General Feature Format (GFF) or Gene Transfer Format (GTF). These files contain key information about the location and structure of genes and transcripts, playing a crucial role in accurate mapping and gene expression quantification. Additionally, RNA-seq data often includes reads that span exon-exon junctions, and the annotation files provide information about splice junctions, allowing for the detection of different isoforms.</p> <p>The alignment and quantification steps can follow two different approaches depending on user preferences: - traditional alignment and quantification; - lightweight alignment and quantification.</p> <p>In RNA-seq analysis, traditional alignment is often performed with splice-aware aligners, which are designed to recognise the splicing process. These aligners can align reads across known splice junctions and detect novel splice sites or alternative splicing events. They use advanced algorithms and optimisation techniques, like reference genome indexing and parallel processing, to achieve accurate and fast alignment. Popular splice-aware aligners include STAR and HISAT2. Once alignment is complete, the next step is quantification, which involves estimating the abundance (number of reads) associated with each gene. Tools like featureCounts, HTSeq, Salmon, and RSEM are commonly used for this purpose.</p> <p>Traditional alignment tools are time-consuming and require substantial computational resources, particularly in terms of memory and CPU usage. Alternatively, the method known as lightweight alignment allows for faster analysis by determining the likely origin of reads without a full, base-by-base alignment. This method is sometimes referred to as quasi-mapping. Lightweight alignment tools like Kallisto, Sailfish, and Salmon avoid full-scale alignment, providing quantification estimates more quickly than traditional splice-aware algorithms, while still maintaining high accuracy. The quantification results from these tools are often called pseudocounts or abundance estimates, which can be used for downstream analysis.</p>"},{"location":"theory/#differential-expression-de-analysis-with-deseq2","title":"Differential expression (DE) analysis with DESeq2","text":"<p>Differential expression analysis is a statistical method for comparing gene expression levels between different experimental conditions, such as disease vs healthy (e.g., tumour tissue vs healthy tissue), treatment vs control (e.g., a sample treated with a specific stimulus, drug, or compound vs an untreated sample), and tissue vs tissue (e.g., brain vs heart). Differential expression analysis aims to assess, for each gene, whether the observed differences in expression between groups are statistically significant, accounting for the variation observed within groups (replicates). This part of the analysis is typically performed in R using various packages that have been developed, such as DESeq2, edgeR, and limma. This tutorial focuses on DESeq2, a popular R package known for its robustness. For more detailed information, see the DESeq2 vignette.</p> <p>The analysis begins with the input data, which generally consist of a matrix obtained during the alignment and quantification step, summarising the expression levels of the different genes in each sample of the dataset. The rows of the matrix typically correspond to genes, and the columns represent the samples. Another essential prerequisite is a metadata table describing the samples.</p>"},{"location":"theory/#quality-control","title":"Quality Control","text":"<p>To ensure robust differential expression results, it is common to start by exploring the sources of variation in the data. DESeq2 provides quality control tools, including Principal Component Analysis (PCA) and hierarchical clustering. PCA is used to reduce the dimensionality of the data, allowing the visualisation of the samples in a lower-dimensional space. In contrast, hierarchical clustering shows the correlation of gene expression for all pairwise combinations of samples in the dataset. These methods can identify groups of samples with similar behaviour, as well as potential outliers or unexpected patterns.</p> <p>Quality control in DESeq2 typically uses variance-stabilised (vst) or regularised log-transformed (rlog) counts. Since raw counts in RNA-seq follow a discrete distribution, which is not suitable for many statistical and machine learning algorithms that assume continuous distributions, transformations such as <code>vst</code> and <code>rlog</code> are applied to stabilise the variance across genes. This stabilisation ensures that, after transformation, genes with both low and high expression levels have variances that are more comparable, making the data more suitable for downstream analyses.</p> <p>Finally, it is often beneficial to filter out genes that are unlikely to show differential expression, such as those with zero counts across samples or extreme count outliers. By filtering out these genes, we can increase the sensitivity of our differential expression analysis and reduce the risk of false positives.</p> <p>Note</p> <p>The <code>vst</code> or <code>rlog</code> transformations are applied to the normalised counts stored in the <code>dds</code> object, which is generated by running either the <code>DESeq()</code> or <code>estimateSizeFactors()</code> function. Since the estimation of size factors is an early step in the <code>DESeq()</code> function, the transformations are generally applied immediately afterwards. </p>"},{"location":"theory/#design-formula","title":"Design Formula","text":"<p>The design formula specifies the sources of variation that the statistical model needs to account for. It defines how the counts will be related to the experimental conditions, allowing the software to model the relationship between gene expression and the factors of interest, such as treatment, time points or batch effects. It is important to specify the main factor of interest as well as additional covariates in the design formula.</p> <p>A well-defined design formula can account for potential confounding variables. For instance, if the experiment includes multiple conditions or batches, specifying these in the design helps to isolate the effect of the primary variable of interest on gene expression. An example is provided below:</p> <pre><code># Basic design with a single factor of interest\n\ndesign = ~ condition\n\n# Design including covariates to control for sex and developmental stage\n\ndesign = ~ sex + developmental_stage + condition\n</code></pre> <p>Note</p> <p>In R, the tilde (<code>~</code>) is used in formula syntax to specify relationships between variables in statistical models. Here, it indicates that gene counts (dependent variable) will be modelled as a function of the specified variables (predictors).</p> <p>The results will not be affected by the order of variables but the common practice is to specify the main source of variation in the last position of the design formula.</p>"},{"location":"theory/#differential-expression-analysis","title":"Differential Expression Analysis","text":"<p>RNA-seq data typically contain a large number of genes with low expression counts, indicating that many genes are expressed at very low levels across samples. At the same time, RNA-seq data exhibit a skewed distribution with a long right tail due to the absence of an upper limit for gene expression levels. This means that while most genes have low to moderate expression levels, a small number are expressed at high levels. Accurate statistical modelling must therefore account for this distribution to avoid misleading conclusions.</p> <p></p> <p>The core of the differential expression analysis is the <code>DESeq()</code> function, a wrapper that streamlines several key steps into a single command. The different functions are listed below:</p> <p></p> <p>Note</p> <p>While <code>DESeq()</code> combines these steps, a user could choose to perform each function separately to have more control over the whole process.</p> <p>The different steps are explained in detail below:</p> <p>1) Normalisation: since DESeq2 compares counts between sample groups for the same gene, it does not need to adjust for gene length. However, it is essential to account for variations in sequencing depth and RNA composition among samples. To normalise the data, DESeq2 utilises size factors, which correct for these variations in library sizes and RNA composition.</p> <p>The size factors are calculated using the median ratio method:</p> <ul> <li>Calculate the geometric mean: For each gene, compute the geometric mean of its counts across all samples. This gives a row-wise geometric mean for each gene;</li> <li>Calculate ratios: Divide each gene's count by its geometric mean to obtain a ratio for each sample;</li> <li>Determine size factors: For each sample, take the median of these ratios (column-wise) to derive the size factors;</li> <li>Normalise counts: Divide each raw count by the corresponding sample size factor to generate normalised counts.</li> </ul> <p>Note</p> <p>While normalised counts are useful for downstream visualisation of results, they should not be used as input for DESeq2. Instead, DESeq2 requires count data in the form of a matrix of integer values.</p> <p>2) Estimate dispersion and gene-wise dispersion: the dispersion is a measure of how much the variance deviates from the mean. The estimation of dispersion is essential to model the variance of the count data. Importantly, RNA-seq data are characterised by overdispersion, where the variance in gene expression levels often exceeds the mean (variance &gt; mean).</p> <p></p> <p>DESeq2 addresses this issue by employing the negative binomial distribution, which generalises the Poisson distribution by introducing an additional dispersion parameter. This parameter quantifies the extra variability present in RNA-seq data, providing a more realistic representation than the Poisson distribution, which assumes equal mean and variance. DESeq2 starts by estimating the common dispersion, a single estimate of dispersion applicable to all genes in the dataset. This estimate provides a baseline for variability across all genes in the dataset. Next, DESeq2 estimates gene-wise dispersion, a separate estimate of dispersion for each individual gene, taking into account that different genes may exhibit varying levels of expression variability due to biological differences.  The dispersion parameter (\u03b1) is related to the mean (\u03bc) and variance of the data, as described by the equation:</p> <p><code>Var = \u03bc + \u03b1 \u22c5 \u03bc\u00b2</code></p> <p>A key feature of DESeq2's dispersion estimates is their negative correlation with the mean and positive correlation with variance. Genes with low expression have higher dispersion values, while genes with high expression tend to have lower dispersion. Additionally, genes sharing similar mean expression levels can exhibit different dispersion estimates based on their variance. To improve the accuracy of dispersion estimates, DESeq2 assumes that genes with similar expression profiles share similar dispersion patterns and leverages this information to refine the estimates.</p> <p>3) Mean-dispersion relationship: this process, known as dispersion fitting, models the relationship between the mean expression level of a gene and its dispersion. In this process, DESeq2 identifies a trend in the dispersion estimates across genes. The fitted curve, typically a smooth curve, describes how dispersion changes as a function of the mean expression level.</p> <p>4) Final dispersion estimates: DESeq2 refines the gene-wise dispersion by shrinking it towards the fitted curve. The \"shrinkage\" helps control for overfitting, particularly in genes with low counts or few replicates, and makes the dispersion estimates more reliable. However, genes with exceptionally high dispersion values are not shrunk because they likely deviate from the modelling assumptions, exhibiting elevated variability due to biological or technical factors. Shrinking these values could lead to false positives.</p> <p>5) Fitting model and testing: the initial step in hypothesis testing involves defining a null hypothesis for each gene. The null hypothesis states that there is no difference in expression between the tested sample groups (LFC == 0). Next, DESeq applies a statistical test to assess whether the null hypothesis is true. DESeq2 fits a generalised linear model (GLM) to the normalised counts using the calculated size factors and final dispersion estimates. A GLM is a flexible extension of linear regression that models the relationship between a response variable (normalised counts) and predictors (e.g., condition). By using a negative binomial distribution, DESeq2's GLM can handle the additional variability in gene expression counts that often occurs in RNA-seq data.Once the model is fit, coefficients are estimated for each sample group along with their standard errors. These coefficients represent the estimated log2 fold changes between groups and serve as the basis for hypothesis testing, using either a Wald test or a Likelihood Ratio Test (LRT), depending on the experimental design:</p> <ul> <li> <p>Wald Test: The Wald test is ideal for simpler experimental designs, such as comparing two conditions (e.g., treated vs untreated). It tests whether the estimated effect size (log2 fold change) of a predictor variable (like treatment) is significantly different from zero. This test provides direct estimates of fold changes with associated p-values, making it computationally efficient for straightforward comparisons.</p> </li> <li> <p>Likelihood Ratio Test (LRT): The LRT is more suitable for complex experimental designs involving multiple variables (e.g., time points, treatments and batches). It compares the fit of two nested models: one with the factor of interest (e.g., treatment) and one without it to assess whether including that factor significantly improves model fit. This approach allows DESeq2 to account for confounding variables and to isolate the effect of specific variables on gene expression, offering flexibility for multi-factor analyses.</p> </li> </ul> <p>When performing multiple tests, such as in the case of RNA-seq data where thousands of genes are tested, the risk of false positives increases. To account for this, DESeq2 employs multiple test correction methods (the Benjamini-Hochberg procedure is the default) to adjust the p-values and control the false discovery rate (FDR). </p> <p>Note</p> <p>The FDR is the expected proportion of false positives among the identified significant results. For example, by setting the FDR cutoff to &lt; 0.05, 5% of genes identified as differentially expressed are expected to be false positives. For instance, if 400 genes are identified as differentially expressed with an FDR cutoff of 0.05, you would expect 20 of them to be false positives. </p> <p>After identifying DE genes using DESeq2, it is essential to interpret the biological significance of these genes through functional analysis. This involves examining the roles of the differentially expressed genes in various biological processes, molecular functions and pathways, providing insights into the underlying mechanisms driving the observed changes in gene expression. This interpretation can help in discovering pathways involved in disease or identifying potential therapeutic targets. Different tools are available to carry out these functional analyses, such as Gene Ontology, Reactome, KEGG, clusterProfiler, g:Profiler and WikiPathways.</p>"}]}